{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Text Similarity</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 1. Resume Preparation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.1 Libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "# custom modules\n",
    "import resume\n",
    "import indeed_job_scraper as indeed\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.2 Extract the Resume and the Objective and Experience Part of the Resume</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data scientist with phd in physics and    industrial experience  two years of working experience in data analysis team of ligo scientific collaboration    m special breakthrough prize winner of over ten years of successful research experience in both theoretical and computational physics  strong problem solving and analytical skills  advanced programming proficiency  certified in data analysis and machine learning data scientist abc corporation   may        may assisted in determining client needs  deliverable design  estimates and feasibility for analytical projects concerning a custom study for a manufacturer who is using the results to support a litigation claim served as an internal resource for jacknife programming and documentation designed and developed small scale deliverables related to the custom study participated in the post project review qip team responsible for results reporting in the appropriate media and creation of supporting monitored products from statistical programs for accuracy  consistency and statistical validity designed and applied statistical and mathematical methods for corporate analytics that were documentation for the client implemented into client facing products data scientist abc corporation maintained automated etl for reporting implemented data mining and machine learning algorithms to describe and predict user behavior on various retailer websites i revamped their  quot predictive marketing quot  process to be more data driven and profitable increase in conversion the new process was able to hone in on more useful user segments that had a significant skills used data cleansing and data analysis using python  scala  r and spark cloud computing on aws automation of reporting\n"
     ]
    }
   ],
   "source": [
    "# Sample Resume\n",
    "pdf_path = 'C:\\\\Users\\\\Charles Lebensdauer\\\\Downloads\\\\sampleres.pdf'\n",
    "# pdf_path = 'C:\\\\Users\\\\Charles Lebensdauer\\\\Downloads\\\\sampleres1.pdf'\n",
    "\n",
    "res = resume.extract_text(pdf_path)\n",
    "res_sec = resume.extract_entity_sections_grad(res)\n",
    "try:\n",
    "    obj = ' '.join(res_sec['objective'])\n",
    "except:\n",
    "    obj = ' '.join(res_sec['resume objective'])\n",
    "try:\n",
    "    exp = ' '.join(res_sec['work experience'])\n",
    "except:\n",
    "    exp = ' '.join(res_sec['experience'])\n",
    "\n",
    "obj_exp = obj + ' ' + exp\n",
    "print(obj_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 2. Job Description Preparation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.2 Using Job Descriptions Posted on Indeed</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job_dict = indeed.get_indeed_job('Data Scientist','Irvine',limit=15)\n",
    "pd.DataFrame(job_dict).to_csv('indeed_job.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_dict=pd.read_csv('indeed_job.csv').to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine Learning Architect</td>\n",
       "      <td>Verys</td>\n",
       "      <td>Santa Ana, CA</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>important notes this position is fully remote ...</td>\n",
       "      <td>Orange|vendors|design|architecture|agile|Orang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst (Mortgage Banking)</td>\n",
       "      <td>Matrix Resources</td>\n",
       "      <td>Santa Ana, CA</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>this nationwide mortgage industry leader has a...</td>\n",
       "      <td>mortgage|Mortgage|Banking|analysis|mortgage|ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Financial Data Analyst w/PE backed Heal...</td>\n",
       "      <td>Alliance Resource Group</td>\n",
       "      <td>Orange, CA</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>senior financial data analyst w healthcare eco...</td>\n",
       "      <td>healthcare|economics|operations|healthcare|ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Staff Data Scientist</td>\n",
       "      <td>Lifesprk</td>\n",
       "      <td>United States</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>lifesprk s product and engineering team is gro...</td>\n",
       "      <td>engineering|System|healthcare|engineering|heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Spireon</td>\n",
       "      <td>Irvine, CA</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=4c35157d313d5...</td>\n",
       "      <td>this is us we have a bold vision to connect   ...</td>\n",
       "      <td>brand|design|reports|transportation|algorithms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Karma Automotive LLC</td>\n",
       "      <td>Irvine, CA</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=f7fd2a35541c6...</td>\n",
       "      <td>overview southern california based karma is mo...</td>\n",
       "      <td>reporting|analyze|reports|Design|modeling|mini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist (Fraud &amp; Game Surveillance)</td>\n",
       "      <td>NCSOFT</td>\n",
       "      <td>Aliso Viejo, CA</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=11cf149979176...</td>\n",
       "      <td>who we are ncsoft is a premiere digital entert...</td>\n",
       "      <td>mobile|design|engineering|improvement|SQL|Tabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Driveway</td>\n",
       "      <td>Aliso Viejo, CA</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=8fccd5560141c...</td>\n",
       "      <td>we are looking for a data scientist who will s...</td>\n",
       "      <td>sales|marketing|analytical|experiments|system|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Scientist / Engineer</td>\n",
       "      <td>AWM Smart Shelf (Adroit Worldwide Media, Inc.)</td>\n",
       "      <td>Aliso Viejo, CA</td>\n",
       "      <td>https://www.indeed.com/company/Adroit-Worldwid...</td>\n",
       "      <td>lead data scientist   engineer   aliso viejo  ...</td>\n",
       "      <td>retail|analytics|analysis|video|AI|AI|analysis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Machine Learning Researcher</td>\n",
       "      <td>BlackBerry</td>\n",
       "      <td>Irvine, CA</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=8e9a26470f63e...</td>\n",
       "      <td>worker sub type regular job description the po...</td>\n",
       "      <td>security|security|statistics|modeling|engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Crossover Health</td>\n",
       "      <td>San Clemente, CA</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=0000e5693c171...</td>\n",
       "      <td>job description  designs  develops and program...</td>\n",
       "      <td>analyze|forecasts|modeling|analysis|experiment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Machine Learning Architect</td>\n",
       "      <td>Verys</td>\n",
       "      <td>Santa Ana, CA</td>\n",
       "      <td>https://www.indeed.com/company/Verys/jobs/Mach...</td>\n",
       "      <td>important notes this position is fully remote ...</td>\n",
       "      <td>Orange|vendors|design|architecture|agile|Orang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Voice of the Customer Sr Data Analyst</td>\n",
       "      <td>loanDepot</td>\n",
       "      <td>Foothill Ranch, CA</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=be7dd55c0e3a0...</td>\n",
       "      <td>loandepot  america s lender  matches borrowers...</td>\n",
       "      <td>Marketing|Finance|Compliance|analysis|reportin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SAP Data Analyst</td>\n",
       "      <td>Fresh n' Lean</td>\n",
       "      <td>Anaheim, CA</td>\n",
       "      <td>https://www.indeed.com/company/Fresh-n'-Lean/j...</td>\n",
       "      <td>summary our organization is implementing sap b...</td>\n",
       "      <td>SAP|migration|SAP|SAP|writing|reports|ERP|SAP|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ULTIMATE STAFFING SERVICES</td>\n",
       "      <td>Irvine, CA</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>key responsibilities data science focusing on ...</td>\n",
       "      <td>AI|Research|AI|healthcare|AI|AI|research|engin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                          Machine Learning Architect   \n",
       "1              Senior Data Analyst (Mortgage Banking)   \n",
       "2   Senior Financial Data Analyst w/PE backed Heal...   \n",
       "3                         Senior Staff Data Scientist   \n",
       "4                                      Data Scientist   \n",
       "5                                      Data Scientist   \n",
       "6          Data Scientist (Fraud & Game Surveillance)   \n",
       "7                                      Data Scientist   \n",
       "8                      Lead Data Scientist / Engineer   \n",
       "9                  Senior Machine Learning Researcher   \n",
       "10                                     Data Scientist   \n",
       "11                         Machine Learning Architect   \n",
       "12              Voice of the Customer Sr Data Analyst   \n",
       "13                                   SAP Data Analyst   \n",
       "14                                     Data Scientist   \n",
       "\n",
       "                                           company            location  \\\n",
       "0                                            Verys       Santa Ana, CA   \n",
       "1                                 Matrix Resources       Santa Ana, CA   \n",
       "2                          Alliance Resource Group          Orange, CA   \n",
       "3                                         Lifesprk       United States   \n",
       "4                                          Spireon          Irvine, CA   \n",
       "5                             Karma Automotive LLC          Irvine, CA   \n",
       "6                                           NCSOFT     Aliso Viejo, CA   \n",
       "7                                         Driveway     Aliso Viejo, CA   \n",
       "8   AWM Smart Shelf (Adroit Worldwide Media, Inc.)     Aliso Viejo, CA   \n",
       "9                                       BlackBerry          Irvine, CA   \n",
       "10                                Crossover Health    San Clemente, CA   \n",
       "11                                           Verys       Santa Ana, CA   \n",
       "12                                       loanDepot  Foothill Ranch, CA   \n",
       "13                                   Fresh n' Lean         Anaheim, CA   \n",
       "14                      ULTIMATE STAFFING SERVICES          Irvine, CA   \n",
       "\n",
       "                                                  url  \\\n",
       "0   https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "1   https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "2   https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "3   https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "4   https://www.indeed.com/rc/clk?jk=4c35157d313d5...   \n",
       "5   https://www.indeed.com/rc/clk?jk=f7fd2a35541c6...   \n",
       "6   https://www.indeed.com/rc/clk?jk=11cf149979176...   \n",
       "7   https://www.indeed.com/rc/clk?jk=8fccd5560141c...   \n",
       "8   https://www.indeed.com/company/Adroit-Worldwid...   \n",
       "9   https://www.indeed.com/rc/clk?jk=8e9a26470f63e...   \n",
       "10  https://www.indeed.com/rc/clk?jk=0000e5693c171...   \n",
       "11  https://www.indeed.com/company/Verys/jobs/Mach...   \n",
       "12  https://www.indeed.com/rc/clk?jk=be7dd55c0e3a0...   \n",
       "13  https://www.indeed.com/company/Fresh-n'-Lean/j...   \n",
       "14  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "\n",
       "                                          description  \\\n",
       "0   important notes this position is fully remote ...   \n",
       "1   this nationwide mortgage industry leader has a...   \n",
       "2   senior financial data analyst w healthcare eco...   \n",
       "3   lifesprk s product and engineering team is gro...   \n",
       "4   this is us we have a bold vision to connect   ...   \n",
       "5   overview southern california based karma is mo...   \n",
       "6   who we are ncsoft is a premiere digital entert...   \n",
       "7   we are looking for a data scientist who will s...   \n",
       "8   lead data scientist   engineer   aliso viejo  ...   \n",
       "9   worker sub type regular job description the po...   \n",
       "10  job description  designs  develops and program...   \n",
       "11  important notes this position is fully remote ...   \n",
       "12  loandepot  america s lender  matches borrowers...   \n",
       "13  summary our organization is implementing sap b...   \n",
       "14  key responsibilities data science focusing on ...   \n",
       "\n",
       "                                               skills  \n",
       "0   Orange|vendors|design|architecture|agile|Orang...  \n",
       "1   mortgage|Mortgage|Banking|analysis|mortgage|ba...  \n",
       "2   healthcare|economics|operations|healthcare|ana...  \n",
       "3   engineering|System|healthcare|engineering|heal...  \n",
       "4   brand|design|reports|transportation|algorithms...  \n",
       "5   reporting|analyze|reports|Design|modeling|mini...  \n",
       "6   mobile|design|engineering|improvement|SQL|Tabl...  \n",
       "7   sales|marketing|analytical|experiments|system|...  \n",
       "8   retail|analytics|analysis|video|AI|AI|analysis...  \n",
       "9   security|security|statistics|modeling|engineer...  \n",
       "10  analyze|forecasts|modeling|analysis|experiment...  \n",
       "11  Orange|vendors|design|architecture|agile|Orang...  \n",
       "12  Marketing|Finance|Compliance|analysis|reportin...  \n",
       "13  SAP|migration|SAP|SAP|writing|reports|ERP|SAP|...  \n",
       "14  AI|Research|AI|healthcare|AI|AI|research|engin...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(job_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Orange|vendors|design|architecture|agile|Orange|technical|database|Java|JavaScript|C|Python|Hadoop|ETL|Spark|Analytics|XGBoost|MXNet|Tensorflow|R|statistics|modeling|algorithms|analytics|AWS|cloud|technical|Schedule|Health|Schedule|AWS|Spark|website|vendors|hadoop|statistics|computer science|schedule|aws|machine learning'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_dict['skills'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "important notes this position is fully remote for the duration of covid    with an eventual return to our orange county office we are only considering local candidates we are not working with third parties at this time  any resumes from vendors will result in removal from our vendor list we are unable to provide sponsorship at this time verys is a multi disciplined technology delivery firm that offers a strategic approach to building software through user centered design  modern development architecture  business alignment all wrapped up in a structured agile environment we build software to be proud of for clients like blizzard  american airlines  kia  and experian right now  we re looking to welcome a new machine learning architect to join our team in orange county  ca in this role  you will work alongside technical leads  developers  qa analysts  and project managers to deliver the quality code that s lead to our stable growth over the last   years if you are excited by solving complex challenges and growing your career within an innovative software services company  we d love to hear from you what you will be doing extract data from a database  cleaning the data  and preparing it for consumption select the best algorithmic approach to serve an ml use case tune the model for development construct data pipelines to maintain the model monitor the model for performance and drift\n",
      "----------------------------------------\n",
      "this nationwide mortgage industry leader has an immediate full time opportunity in santa ana  ca for a senior data analyst with deep mortgage banking experience will be responsible for quantitative and data analysis across mortgage banking activities   research  develop and build analysis data sets to support sales and operations management team responsibilities include developing sql queries stored procedures to retrieve and analyze data to support digitization researching to identify underlying root cause for issues using data building dashboards to continuously monitor implemented solutions coordinating with operation management to gather suggestions for improvements performing ad hoc analytical requests and research projects for internal parties providing feedback to senior management for identified problem areas and providing proactive solutions this position requires years experience as a data analyst within the mortgage banking industry proficient in the manipulation and use of large and complex databases strong understanding of sql database and data warehouse concepts and structures strong quantitative skills with a proven ability to translate analysis into meaningful insights proficient in sql  power bi and ms office products  excel  word  powerpoint including pivot  graph and slicer techniques ability to create  compose and edit written materials and presentations excellent verbal  written and interpersonal communication skills\n",
      "----------------------------------------\n",
      "senior financial data analyst w healthcare economics background this is an excellent opportunity for a candidate that is looking to take their career to the next level and come in on the ground floor in a fast moving  dynamic company the position is broad and will be exposed to all aspects of operations great opportunity for someone to broaden their skill set and get exposure to a very sophisticated  technology driven healthcare company job description the sr  financial data analyst will review  analyze  and report on data from the company s reporting system which includes medical claims data  utilization data  pharmacy data  and other sources such as gl and accounting related entries this person will be responsible for creating adhoc reports and models to support the analysis of product line profitability  gross margin  and possible market expansion opportunities there will also be significant involvement in working cross functionally with departments  so great communication skills are key for success in this role job duties reconcile and verify the integrity of yearly and monthly financial data to the general ledger work with the fp amp a team to incorporate budget data and assumptions into the company s reporting system validate the integrity of claim payment and analyze contract rate trending impact and anomalies validate and reconcile key authorization admit and bed day metrics to actual paid claim data support regional vp s in providing analysis of monthly data and ad hoc reporting of key performance indicators support finance and operations in developing predictive kpi s to better forecast and manage the business work with all levels of staff to direct  assist  and explain financial analysis processes read and interpret contracts with regards to risk pool definitions for revenue  expense  carve outs and calculations update risk pool calculations and definitions for newly delegated entities  as well as contract amendments for existing entities analyze key drivers of risk pool surplus or deficits and communicate to appropriate internal parties\n",
      "----------------------------------------\n",
      "lifesprk s product and engineering team is growing we are having great success building custom solutions for our teammates in order to bring to light the first ever life experience alternative delivery system  leads our focus  and our passion  is lifecare  not just healthcare come join us and be part of building something truly meaningful from the ground up with a diverse team of committed  humble  awesome people all fully distributed from anywhere in the country lifesprk  headquartered in minneapolis  with our head of engineering in boulder colorado   has been sparking lives for    years and it is time to take our  whole person senior care  model to a greater and greater reach and to do that  we need you to come and build the  best in class  platform for whole person health as our most senior data scientist you will provider leadership across our data science and analytics efforts with your expertise we will create predictive insights to support leads in this new role  you will be laying the foundations of how we unlock the insights hidden within all our data you will help to define our strategies around data governance  security  analysis and ai ml you will bring your passion for how data can transform lives this hands on role will require the development of solid processes around data acquisition  analysis and life cycle management have your favorite toolset we would love to hear about how you have done this in the past this role requires excellent communication skills  you will be our master storyteller as you identify new business questions  develop analytical methods to answer those questions and conduct experiments to validate our assumptions all while being hyper focused on quality outcomes for our members come use your superpowers for good and join us in sparking lives how you will spend your days building a collaborative and service oriented data and analytics discipline that empowers subject matter experts with data and tools throughout the organization delivering and supporting the delivery of retroactive analysis in order to provide deeper understanding of the leads initiatives designing the system architecture for the data and analytics environment to ensure data quality system stability and extensibility scalability maintainability collaborating with data engineering team to develop a comprehensive data architecture building and testing predictive models that increase leads efficacy presenting compelling reports that support the business with powerful stories and statistically sound analysis leveling up all those around you in how to think about data and analysis\n",
      "----------------------------------------\n",
      "this is us we have a bold vision to connect    million vehicles by our customers come first we lead through innovation we win as one we act with integrity we adhere to our brand promise   to make the complex simple  the future predictable  and our customers successful with nearly   million connected vehicles today spireon is an exciting player in the growing connected car and internet of things  iot  technology categories we help people and businesses track and protect their most important assets with vehicle intelligence solutions that gather big data and provide the critical insights with easy to use dashboards and apps this is you we are looking for a data scientist  machine learning engineer to design and build convolutional neural networks for smart sensors spireon develops computer vision based smart sensors to detect environment and reports for the transportation sector as a machine learning engineer  you will implement cnn algorithms to run on smart sensors   you must be able to work across multiple teams to ensure project objectives are met responsibilities design and develop algorithms for challenging vision classification and detections problems research and develop statistical learning models for data analysis implementation of computer vision and ml algorithms collect data and analyze real world data deploy ml systems  inference at the edge   monitor metrics prototyping ml algorithms collaborate with product management and engineering departments to understand company needs and devise possible solutions keep up to date with latest technology trends communicate results and ideas to key decision makers\n",
      "----------------------------------------\n",
      "overview southern california based karma is more than just a car company although we are best known as a creator of soul stirring luxury electric vehicles  karma has emerged as a high tech incubator offering innovators a perfect platform to prove their emerging technologies every revero is designed at our headquarters in irvine and created with great individual care and world class craftsmanship at the karma innovation and customization center in moreno valley  ca the data scientist reporting to the manager  data sciences and innovation  is responsible for data collection analyze  extract  normalize  and label relevant data from multiple sources to provide interpretation and visualizations reports around key data driven projects responsibilities design and build new data set processes for modeling  data mining  and production purposes determine new ways to improve data and search quality  and predictive capabilities perform and interpret data studies and product experiments concerning new data sources or new uses for existing data sources develop prototypes  proof of concepts  algorithms  predictive models  and custom analysis create visualizations and reports to show insights obtained from data mining efforts interact with multiple internal and external sources in support of ongoing and proof of concept projects ensure timely  accurate and credible information is provided and interpreted and distilled into action driven information for diverse audiences attend trade shows  conferences and learning opportunity to familiarize with the industry leading trends in data sciences and predictive analytics to help drive karma s data sciences and technology department development other duties  as assigned\n",
      "----------------------------------------\n",
      "who we are ncsoft is a premiere digital entertainment company and global publisher with worldwide locations and more than       employees focused on bringing extraordinary games to life for millions of fans around the world established in      and headquartered in seoul  south korea  we quickly became a key leader in online games best known for critically acclaimed franchises including lineage  aion  guild wars  and blade  amp  soul  ncsoft is also one of the world s top mobile developers with lineage  m occupying the    grossing revenue slot on google play our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same we are looking for a data scientist to join our fraud and game surveillance unit and help us keep our games safe and fun for all our players we are looking for someone with a burning curiosity about our players and our games  someone who can go deep to find answers and bring back actionable insights the ideal candidate is equally passionate about machine learning and improving the player experience this role will partner closely with design  engineering  and customer service to help create and maintain a safe and welcoming environment for all our players you will help build tools to detect toxic chat and sift pvp match records to find cheats and bots this is your chance to help make our games safer  friendlier  and more fun why join the customer care team you are a passionate gamer  you will join us in supporting multiple aaa titles we are all gamers and we love helping our fellow players you enjoy creating positive user experiences this is at the core of what we do you think about how we best prevent players from having to contact us and how to make their interactions with our team seamless you learn from negative feedback and get satisfaction from positive outcomes you love a challenge you will encounter daily opportunities to overcome new challenges and problems you thrive in a fast pasted  high volume work environment you love to share your knowledge and experience  we know our games and our player base inside and out and we leverage that knowledge to drive improvement you are good at finding ways to best impart your knowledge to internal teams and our customers\n",
      "----------------------------------------\n",
      "we are looking for a data scientist who will support our product  sales  leadership and marketing teams with insights gained from analyzing company data the ideal candidate will be intricately involved in running analytical experiments in a methodical manner and will regularly evaluate alternate models via theoretical approaches they must have a proven ability to drive business results with their data based insights primary responsibilities understanding data flow in a large  distributed system designing  coding and executing data investigations performing robust statistical analyses producing internal presentations  customer reports and visualizations to summarize the conclusions handle a diverse set of problems ranging from probabilistic interference on phone trajectories  data fusion between noisy sensors  modeling and classification of driving behavior  and data visualization all other duties as assigned\n",
      "----------------------------------------\n",
      "lead data scientist   engineer   aliso viejo  ca awm smart shelf is reinventing retail and looking for smart  talented people to help build on our current and future data and analytics platforms  pipelines  and machine learning models our solutions encompass a wide range of data such as real time computer vision and deep learning that enables an understanding of what shoppers and workers are doing  e g movement  actions  product selection  etc awm frictionless  shopping  cashierless checkout demographic data captured via anonymous facial analysis ads video playback and effectiveness product placement and pricing the ideal candidate will have the ability to use modern techniques to understand and interpret data  reaching meaningful conclusions based on solid premises predict optimizations both in real time and via big data processing handle large and rapidly growing data sets job duties contributing to the development and maintenance of data pipelines as well as creation of new ones based on ai computer vision and other data sources validation of ai models and big data analysis performing ad hoc analysis on proprietary datasets for internal and external stakeholders annotating proprietary datasets and giving direction to data labelers performing exploratory analysis on data to find trends training and evaluating various machine learning models\n",
      "----------------------------------------\n",
      "worker sub type regular job description the position we are seeking a data scientist to help develop state of the art machine learning techniques to solve long standing problems in computer security we discover novel ml techniques and applications  build systems to handle petabytes of ludicrously high dimensional data  and protect people from bad guys with machine learning at the heart blackberry protect  the data science team is a critical  highly visible  and high impact team within the company the team brings together experts from machine learning  stats  computer science  computer security  and various applied sciences  with backgrounds including deep learning  bayesian statistics  time series modeling  topology  scalable data processing  and software engineering you don t need prior experience in security  although it helps the right candidate will be able to gain domain expertise on the job  surrounded by some of the computer security industry s leading minds however  for this particular hire  we do require the candidate to have significant deep learning expertise what you will do invent novel machine learning techniques to solve important problems in computer security improve upon existing machine learning techniques discover ways to strengthen machine learning models against adversarial attacks write code that scales to very large datasets  often with millions of dimensions collaborate closely with internal product and engineering teams to help turn ml research prototypes into new products or features publish papers and present research at conferences  including ml ai stats conferences  as well as security conferences like black hat  defcon  and rsa stay abreast of the latest publications and state of the art techniques in relevant research communities  e g   ml and stats consult with other teams on applications of data science collaborate with other data scientists on the team to help accomplish all of the above\n",
      "----------------------------------------\n",
      "job description  designs  develops and programs methods  processes  and systems to consolidate and analyze unstructured  diverse  big data  sources to generate actionable insights and solutions for client services and product enhancement constructs forecasts and advance modeling to recommend strategic tactical plans based on business data and market knowledge interacts with product and service teams to identify questions and issues for data analysis and experiments develops and codes software programs  algorithms and automated processes to cleanse  integrate and evaluate large datasets from multiple disparate sources identifies meaningful insights from large data and metadata sources  interprets and communicates insights and findings from analysis and experiments to product  service  and business managers job duties operational excellence design and deployment of models  quantitative analysis and design queries for all clients and internal teams leverages existing bi reporting and analysis packages to extend incremental value and business intelligence capabilities develops and disseminates reports and forecasts to recommend strategic   tactical plans based on business data and market knowledge  communicates findings from analysis to inform action works within interdisciplinary teams across complex issues of diverse scope where analysis of situation or data requires evaluation of a variety of factors  including an understanding of current business trends and overall market context applies business intelligence tools and processes to enable design and deployment of consistent processes and systems to enable cross functional strategy deployment across the organization products services conducts analysis utilizing business intelligence methods and approaches in support of products necessary for critical expansion of services  including care management  virtual care  targeted clinical programming  and related services insures business intelligence integration for technology implementation for each health center according to xo established product parameters to enable operational processes\n",
      "----------------------------------------\n",
      "important notes this position is fully remote for the duration of covid    with an eventual return to our orange county office we are only considering local candidates we are not working with third parties at this time  any resumes from vendors will result in removal from our vendor list we are unable to provide sponsorship at this time verys is a multi disciplined technology delivery firm that offers a strategic approach to building software through user centered design  modern development architecture  business alignment all wrapped up in a structured agile environment we build software to be proud of for clients like blizzard  american airlines  kia  and experian right now  we re looking to welcome a new machine learning architect to join our team in orange county  ca in this role  you will work alongside technical leads  developers  qa analysts  and project managers to deliver the quality code that s lead to our stable growth over the last   years if you are excited by solving complex challenges and growing your career within an innovative software services company  we d love to hear from you what you will be doing extract data from a database  cleaning the data  and preparing it for consumption select the best algorithmic approach to serve an ml use case tune the model for development construct data pipelines to maintain the model monitor the model for performance and drift\n",
      "----------------------------------------\n",
      "loandepot  america s lender  matches borrowers through technology and high touch customer care with the credit they need to fuel their lives while there are many loan touch career opportunities within loandepot  we could not take care of our employees  nor our customers  without the amazing support of our corporate teams from hr  amp  marketing to finance  amp  compliance   teamloandepot is always searching for the best talent out there with over      billion in funded loans since inception  the evolution  amp  enthusiasm is not slowing down anytime soon come join us loandepot   we are america s lender position summary responsible for overseeing the ingestion  analysis and reporting of voice of the customer data  metrics and information helps to deliver high quality and timely information in support of a wide range of initiatives including operation control  performance improvement  compliance  regulatory reporting  and all other organizational strategies ensures the performance of all duties in accordance with the company s policies and procedures  all u s  state and federal laws and regulations  wherein the company operates responsibilities analyzes said data in real time and creates feedback loops for emerging  high priority issues and findings assists with improving the way in which data and information is ingested by the department creates departmental reporting  including analysis  and shares findings with management responsible for assisting with department audits  identifying trends  and determining system improvements\n",
      "----------------------------------------\n",
      "summary our organization is implementing sap business one the position is the lead for collecting source master data  managing the data clean up  and migration to sap b  templates customizing and maintaining sap b   writing reports  and providing user support candidate should have experience working with erp systems for small and midsize enterprises  preferably sap business one this role requires the candidate to support our internal business systems and processes  including basic it functions experience with sql  microsoft excel and reporting required this is a full time  on site role essential functions collecting source master data from legacy systems and spreadsheets master data cleansing and transformation for migration templates to sap business one analyses  data validation  data mining master data gatekeeper process set up understand and optimize utilization of sap b  workflows collaborate with sap partner support to resolve problems and improve processes in sap implement systems  technologies  and processes to grow and expand the effectiveness of the systems review data  test  and implementation in sandbox environment and migrate to production environment validate the inputs  quantities  units of measure  outputs and any associated key data attributes as they create full product recipes and overall production data workflows maintain data integrity in systems by running queries and analyzing data create  document  maintain  and support a variety of reports and queries develop user procedures  guidelines  and documentation train new system users on new processes and functionality creating and building bill of materials  bom  in sap business one to support supply chain and operations teams perform additional tasks as needed competencies  desire to grow and learn new skills  positive attitude  take responsibility  self confident  controls emotions  effective communicator  gives their absolute best  respectful  team orientated\n",
      "----------------------------------------\n",
      "key responsibilities data science focusing on the aspect of applying machine learning and ai capabilities to the clinical research function at the company this position will not only expose you to the emerging demand and growth of ml and ai in healthcare but allow you to experience and take part in its development the data scientist will work directly with the principal data scientist in the business excellence ai group the primary focus will be to assist the principal data scientist to embark on various ml and ai projects that hinge on the prospect of solving challenging business problems projects are ranging from creating data driven dashboards to building complex prediction models  image detection processing  and developing natural language processing capabilities conduct advanced research and engineering for machine learning  ml  and nlp solutions for healthcare related topics work with large scale healthcare datasets to develop and test your ml and nlp models take advantage of models developed internally and available from the community to solve research problems in healthcare work closely with the ai research team as well as the clinical team to transfer your proof of concept research prototypes into meaningful features within our products skills knowledge of python and sql required knowledge of bi preferred knowledge of tableau preferred hands on experience with data pre processing  modeling  and visualization proficient in python hands on experience with sql and nosql databases knowledge of machine learning libraries  scikit learn  tensorflow  and pytorch prior experience in working with tableau and or power bi good communication and team working skills experience of working with aws is a plus education  amp  experience\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for desc in job_dict['description']:\n",
    "    print(desc)\n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 3. Text Similarity</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.1. CountVectorizer + Cosine Similarity</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Libraries</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Using the Whole Resume</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.043923377990722656 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "cv_cs = {'job_full_resume':[],'count_vectorizer_full_resume':[]}\n",
    "for (job,description) in jobs_no_title.items():\n",
    "    comp_text = [res, description]\n",
    "    cv = CountVectorizer(stop_words='english')\n",
    "    cv_fit = cv.fit_transform(comp_text)\n",
    "    cv_cs['job_full_resume'].append(job)\n",
    "    cv_cs['count_vectorizer_full_resume'].append(cosine_similarity(cv_fit)[0][1])\n",
    "df_cv_r = pd.DataFrame(cv_cs).sort_values(by='count_vectorizer_full_resume',ascending=False).reset_index(drop=True)\n",
    "print(time.time()-t,'seconds')\n",
    "# df_cv_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Using the Objective & Experience Sections of the Resume</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.047899723052978516 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "cv_cs = {'job':[],'count_vectorizer':[]}\n",
    "for (job,description) in jobs_no_title.items():\n",
    "    comp_text = [obj_exp, description]\n",
    "    cv = CountVectorizer(stop_words='english')\n",
    "    cv_fit = cv.fit_transform(comp_text)\n",
    "    cv_cs['job'].append(job)\n",
    "    cv_cs['count_vectorizer'].append(cosine_similarity(cv_fit)[0][1])\n",
    "df_cv = pd.DataFrame(cv_cs).sort_values(by='count_vectorizer',ascending=False).reset_index(drop=True)\n",
    "print(time.time()-t,'seconds')\n",
    "# df_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_diff(data):\n",
    "    df_empty = pd.DataFrame(index=data.index, columns=data.columns).fillna(value='')\n",
    "    comp = (data.iloc[:,0] == data.iloc[:,2]).apply(lambda x : '' if x else 'background-color: #bbe6ed')\n",
    "    df_empty.iloc[:,0] = comp\n",
    "    df_empty.iloc[:,2] = comp\n",
    "    return df_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_372179f8_e182_11ea_aa13_f06e0be3d7d1row6_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_372179f8_e182_11ea_aa13_f06e0be3d7d1row6_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_372179f8_e182_11ea_aa13_f06e0be3d7d1row7_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_372179f8_e182_11ea_aa13_f06e0be3d7d1row7_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_372179f8_e182_11ea_aa13_f06e0be3d7d1row8_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_372179f8_e182_11ea_aa13_f06e0be3d7d1row8_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_372179f8_e182_11ea_aa13_f06e0be3d7d1row9_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_372179f8_e182_11ea_aa13_f06e0be3d7d1row9_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }</style><table id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >job_full_resume</th>        <th class=\"col_heading level0 col1\" >count_vectorizer_full_resume</th>        <th class=\"col_heading level0 col2\" >job</th>        <th class=\"col_heading level0 col3\" >count_vectorizer</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row0_col0\" class=\"data row0 col0\" >Data Scientist</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row0_col1\" class=\"data row0 col1\" >0.477626</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row0_col2\" class=\"data row0 col2\" >Data Scientist</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row0_col3\" class=\"data row0 col3\" >0.477106</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row1_col0\" class=\"data row1 col0\" >Data Analyst</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row1_col1\" class=\"data row1 col1\" >0.420665</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row1_col2\" class=\"data row1 col2\" >Data Analyst</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row1_col3\" class=\"data row1 col3\" >0.424797</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row2_col0\" class=\"data row2 col0\" >User Experience (UX) Designer</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row2_col1\" class=\"data row2 col1\" >0.178566</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row2_col2\" class=\"data row2 col2\" >User Experience (UX) Designer</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row2_col3\" class=\"data row2 col3\" >0.189792</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row3_col0\" class=\"data row3 col0\" >Web Developer</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row3_col1\" class=\"data row3 col1\" >0.174702</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row3_col2\" class=\"data row3 col2\" >Web Developer</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row3_col3\" class=\"data row3 col3\" >0.189388</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row4_col0\" class=\"data row4 col0\" >Business Analyst</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row4_col1\" class=\"data row4 col1\" >0.155636</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row4_col2\" class=\"data row4 col2\" >Business Analyst</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row4_col3\" class=\"data row4 col3\" >0.154842</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row5_col0\" class=\"data row5 col0\" >Computer Programmer</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row5_col1\" class=\"data row5 col1\" >0.138441</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row5_col2\" class=\"data row5 col2\" >Computer Programmer</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row5_col3\" class=\"data row5 col3\" >0.148704</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row6_col0\" class=\"data row6 col0\" >Graphic Designer</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row6_col1\" class=\"data row6 col1\" >0.131417</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row6_col2\" class=\"data row6 col2\" >Fashion Designer</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row6_col3\" class=\"data row6 col3\" >0.144647</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row7_col0\" class=\"data row7 col0\" >Fashion Designer</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row7_col1\" class=\"data row7 col1\" >0.127814</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row7_col2\" class=\"data row7 col2\" >Graphic Designer</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row7_col3\" class=\"data row7 col3\" >0.143778</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row8_col0\" class=\"data row8 col0\" >Social Media Marketing Specialist</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row8_col1\" class=\"data row8 col1\" >0.123212</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row8_col2\" class=\"data row8 col2\" >Business Consultant</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row8_col3\" class=\"data row8 col3\" >0.134100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row9_col0\" class=\"data row9 col0\" >Business Consultant</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row9_col1\" class=\"data row9 col1\" >0.119349</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row9_col2\" class=\"data row9 col2\" >Social Media Marketing Specialist</td>\n",
       "                        <td id=\"T_372179f8_e182_11ea_aa13_f06e0be3d7d1row9_col3\" class=\"data row9 col3\" >0.129412</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14855212788>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.concat([df_cv_r,df_cv],axis=1).head(10)\n",
    "temp.style.apply(color_diff,axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of count vectorizer, using the full resume or the objective & experience section does not affect the result that much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.2. TfidfVectorizer + Cosine Similarity</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Libraries</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Using the Whole Resume</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06582522392272949 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "tv_cs = {'job_full_resume':[],'tfidf_vectorizer_full_resume':[]}\n",
    "for (job,description) in jobs_no_title.items():\n",
    "    comp_text = [res, description]\n",
    "    tv = TfidfVectorizer(use_idf=True, stop_words='english')\n",
    "    tv_fit = tv.fit_transform(comp_text)\n",
    "    tv_cs['job_full_resume'].append(job)\n",
    "    tv_cs['tfidf_vectorizer_full_resume'].append(cosine_similarity(tv_fit)[0][1])\n",
    "df_tv_r = pd.DataFrame(tv_cs).sort_values(by='tfidf_vectorizer_full_resume',ascending=False).reset_index(drop=True)\n",
    "print(time.time()-t,'seconds')\n",
    "# df_tv_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Using the Objective & Experience Sections of the Resume</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_cs = {'job':[],'tfidf_vectorizer':[]}\n",
    "for (job,description) in jobs_no_title.items():\n",
    "    comp_text = [obj_exp, description]\n",
    "    tv = TfidfVectorizer(use_idf=True, stop_words='english')\n",
    "    tv_fit = tv.fit_transform(comp_text)\n",
    "    tv_cs['job'].append(job)\n",
    "    tv_cs['tfidf_vectorizer'].append(cosine_similarity(tv_fit)[0][1])\n",
    "df_tv = pd.DataFrame(tv_cs).sort_values(by='tfidf_vectorizer',ascending=False).reset_index(drop=True)\n",
    "# df_tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row6_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row6_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row7_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row7_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row9_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row9_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }</style><table id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >job_full_resume</th>        <th class=\"col_heading level0 col1\" >tfidf_vectorizer_full_resume</th>        <th class=\"col_heading level0 col2\" >job</th>        <th class=\"col_heading level0 col3\" >tfidf_vectorizer</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row0_col0\" class=\"data row0 col0\" >Data Scientist</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row0_col1\" class=\"data row0 col1\" >0.321314</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row0_col2\" class=\"data row0 col2\" >Data Scientist</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row0_col3\" class=\"data row0 col3\" >0.321460</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row1_col0\" class=\"data row1 col0\" >Data Analyst</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row1_col1\" class=\"data row1 col1\" >0.279361</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row1_col2\" class=\"data row1 col2\" >Data Analyst</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row1_col3\" class=\"data row1 col3\" >0.279848</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row2_col0\" class=\"data row2 col0\" >Web Developer</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row2_col1\" class=\"data row2 col1\" >0.104516</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row2_col2\" class=\"data row2 col2\" >Web Developer</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row2_col3\" class=\"data row2 col3\" >0.113473</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row3_col0\" class=\"data row3 col0\" >User Experience (UX) Designer</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row3_col1\" class=\"data row3 col1\" >0.102723</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row3_col2\" class=\"data row3 col2\" >User Experience (UX) Designer</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row3_col3\" class=\"data row3 col3\" >0.108392</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row4_col0\" class=\"data row4 col0\" >Business Analyst</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row4_col1\" class=\"data row4 col1\" >0.090924</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row4_col2\" class=\"data row4 col2\" >Business Analyst</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row4_col3\" class=\"data row4 col3\" >0.090215</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row5_col0\" class=\"data row5 col0\" >Computer Programmer</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row5_col1\" class=\"data row5 col1\" >0.081557</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row5_col2\" class=\"data row5 col2\" >Computer Programmer</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row5_col3\" class=\"data row5 col3\" >0.087828</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row6_col0\" class=\"data row6 col0\" >Graphic Designer</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row6_col1\" class=\"data row6 col1\" >0.077519</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row6_col2\" class=\"data row6 col2\" >Fashion Designer</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row6_col3\" class=\"data row6 col3\" >0.086567</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row7_col0\" class=\"data row7 col0\" >Fashion Designer</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row7_col1\" class=\"data row7 col1\" >0.076358</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row7_col2\" class=\"data row7 col2\" >Graphic Designer</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row7_col3\" class=\"data row7 col3\" >0.084952</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row8_col0\" class=\"data row8 col0\" >Social Media Marketing Specialist</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row8_col1\" class=\"data row8 col1\" >0.073601</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row8_col2\" class=\"data row8 col2\" >Social Media Marketing Specialist</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row8_col3\" class=\"data row8 col3\" >0.077067</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row9_col0\" class=\"data row9 col0\" >Business Consultant</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row9_col1\" class=\"data row9 col1\" >0.064745</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row9_col2\" class=\"data row9 col2\" >Project Manager</td>\n",
       "                        <td id=\"T_6ae08a24_e182_11ea_b0b0_f06e0be3d7d1row9_col3\" class=\"data row9 col3\" >0.076817</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14855255cc8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp = pd.concat([df_tv_r,df_tv],axis=1).head(10)\n",
    "comp.style.apply(color_diff,axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, in the case of TFIDF vectorizer, using the full resume or the objective & experience section does not affect the result that much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.3 GloVe + Spacial Cosine Angle</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Load GloVe Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model...\n",
      "Done. 400000  words loaded!\n",
      "8.165138959884644 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "gloveFile = \"glove\\\\glove.6B.50d.txt\"\n",
    "\n",
    "def loadGloveModel(gloveFile):\n",
    "    print('Loading Glove Model...')\n",
    "    with open(gloveFile, encoding='utf-8' ) as f:\n",
    "        content = f.readlines()\n",
    "    model = {}\n",
    "    for line in content:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print ('Done.',len(model),' words loaded!')\n",
    "    return model\n",
    "\n",
    "model = loadGloveModel(gloveFile)\n",
    "print(time.time()-t,'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Libraries</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "#nltk\n",
    "import re\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^A-Za-z]',' ',text)\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "#     no_stopwords = ' '.join([w for w in words if w not in stopwords_list])\n",
    "#     no_stopwords = list(set([w for w in words if w not in stopwords_list]))\n",
    "    no_stopwords = [w for w in words if w not in stopwords_list]\n",
    "    return no_stopwords\n",
    "\n",
    "# This function is needed since experience contains words glove does not\n",
    "def glove_select(text):\n",
    "    words = preprocess(text)\n",
    "    common_wds = set(words) & set(model.keys())\n",
    "    words = [wd for wd in words if wd in common_wds]\n",
    "    return words\n",
    "\n",
    "def spacial_cosine_angle(s1, s2):\n",
    "    vector_1 = np.mean([model[word] for word in s1],axis=0)\n",
    "    vector_2 = np.mean([model[word] for word in s2],axis=0)\n",
    "    cosine = scipy.spatial.distance.cosine(vector_1, vector_2)\n",
    "#     print('Word Embedding method with a cosine distance asses that our two sentences are similar to',round((1-cosine)*100,2),'%')\n",
    "    return 1-cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method:\n",
    "<ol>\n",
    "    <li>Replaces word in the text with a vector that represents that word in the GloVe model</li>\n",
    "    <li>Calculate the average vector of all word vectors in the text</li>\n",
    "    <li>Calculate the cosine distance between the average vectors of two texts</li>\n",
    "</ol>\n",
    "<br>\n",
    "Although this method is relatively quick, uploading the GloVe model to the web might be a challenge and cause significant loading time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d701d536cc02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mres_process\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglove_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# obj_exp_process\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-0d567d94948d>\u001b[0m in \u001b[0;36mglove_select\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mglove_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mcommon_wds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mwd\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mwd\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mwd\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcommon_wds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "res_process = glove_select(res)\n",
    "# obj_exp_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obj_exp_process = glove_select(obj_exp)\n",
    "# obj_exp_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0472307205200195 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "glove = {'job_full_resume':[],'glove_full_resume':[]}\n",
    "for (job,description) in jobs_no_title.items():\n",
    "    job_process = glove_select(description)\n",
    "    glove['job_full_resume'].append(job)\n",
    "    glove['glove_full_resume'].append(spacial_cosine_angle(job_process,res_process))\n",
    "df_glove_r = pd.DataFrame(glove).sort_values(by='glove_full_resume',ascending=False).reset_index(drop=True)\n",
    "print(time.time()-t,'seconds')\n",
    "# df_glove_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1239972114562988 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "glove = {'job':[],'glove':[]}\n",
    "for (job,description) in jobs_no_title.items():\n",
    "    job_process = glove_select(description)\n",
    "    glove['job'].append(job)\n",
    "    glove['glove'].append(spacial_cosine_angle(job_process,obj_exp_process))\n",
    "df_glove = pd.DataFrame(glove).sort_values(by='glove',ascending=False).reset_index(drop=True)\n",
    "print(time.time()-t,'seconds')\n",
    "# df_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row1_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row1_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row2_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row2_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row3_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row3_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row4_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row4_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row6_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row6_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row7_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row7_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row8_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row8_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row9_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row9_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }</style><table id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >job_full_resume</th>        <th class=\"col_heading level0 col1\" >glove_full_resume</th>        <th class=\"col_heading level0 col2\" >job</th>        <th class=\"col_heading level0 col3\" >glove</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row0_col0\" class=\"data row0 col0\" >Data Scientist</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row0_col1\" class=\"data row0 col1\" >0.978690</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row0_col2\" class=\"data row0 col2\" >Data Scientist</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row0_col3\" class=\"data row0 col3\" >0.979959</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row1_col0\" class=\"data row1 col0\" >Computer Programmer</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row1_col1\" class=\"data row1 col1\" >0.970485</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row1_col2\" class=\"data row1 col2\" >Data Analyst</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row1_col3\" class=\"data row1 col3\" >0.973099</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row2_col0\" class=\"data row2 col0\" >Data Analyst</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row2_col1\" class=\"data row2 col1\" >0.968983</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row2_col2\" class=\"data row2 col2\" >Computer Programmer</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row2_col3\" class=\"data row2 col3\" >0.971956</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row3_col0\" class=\"data row3 col0\" >Web Developer</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row3_col1\" class=\"data row3 col1\" >0.965311</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row3_col2\" class=\"data row3 col2\" >Business Analyst</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row3_col3\" class=\"data row3 col3\" >0.964259</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row4_col0\" class=\"data row4 col0\" >Business Analyst</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row4_col1\" class=\"data row4 col1\" >0.955577</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row4_col2\" class=\"data row4 col2\" >Web Developer</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row4_col3\" class=\"data row4 col3\" >0.961016</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row5_col0\" class=\"data row5 col0\" >User Experience (UX) Designer</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row5_col1\" class=\"data row5 col1\" >0.955107</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row5_col2\" class=\"data row5 col2\" >User Experience (UX) Designer</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row5_col3\" class=\"data row5 col3\" >0.960939</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row6_col0\" class=\"data row6 col0\" >Social Media Marketing Specialist</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row6_col1\" class=\"data row6 col1\" >0.948970</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row6_col2\" class=\"data row6 col2\" >Industrial Engineer</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row6_col3\" class=\"data row6 col3\" >0.949891</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row7_col0\" class=\"data row7 col0\" >Graphic Designer</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row7_col1\" class=\"data row7 col1\" >0.946995</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row7_col2\" class=\"data row7 col2\" >Social Media Marketing Specialist</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row7_col3\" class=\"data row7 col3\" >0.949283</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row8_col0\" class=\"data row8 col0\" >Content Writer/Editor</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row8_col1\" class=\"data row8 col1\" >0.945868</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row8_col2\" class=\"data row8 col2\" >Graphic Designer</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row8_col3\" class=\"data row8 col3\" >0.949175</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row9_col0\" class=\"data row9 col0\" >Industrial Engineer</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row9_col1\" class=\"data row9 col1\" >0.939051</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row9_col2\" class=\"data row9 col2\" >Project Manager</td>\n",
       "                        <td id=\"T_497f4ea8_e183_11ea_a489_f06e0be3d7d1row9_col3\" class=\"data row9 col3\" >0.938822</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x148554bba48>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp = pd.concat([df_glove_r,df_glove],axis=1).head(10)\n",
    "comp.style.apply(color_diff,axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4.4 Gensim Models + Similarity Matrix</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Libraries</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7428734302520752\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "# import gensim\n",
    "import time\n",
    "import gensim.downloader as api\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.matutils import softcossim \n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from gensim.models.keyedvectors import WordEmbeddingSimilarityIndex\n",
    "from gensim.similarities import SparseTermSimilarityMatrix,SoftCosineSimilarity\n",
    "print(time.time() - t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>4.4.1 FastText 300</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Load FastText Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FastText model...\n",
      "Loading finished. 283.11531043052673 seconds taken.\n"
     ]
    }
   ],
   "source": [
    "print('Loading FastText model...')\n",
    "t = time.time()\n",
    "\n",
    "# Download the FastText model\n",
    "fasttext_model300 = api.load('fasttext-wiki-news-subwords-300')\n",
    "print('Loading finished.',str(time.time()-t),'seconds taken.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_description = []\n",
    "for (job,description) in jobs_no_title.items():\n",
    "    job_title.append(job)\n",
    "    job_description.append(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123.84601998329163\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "comp_text = [res] + job_description\n",
    "corpus = [simple_preprocess(txt) for txt in comp_text]\n",
    "dictionary = corpora.Dictionary(corpus)\n",
    "text_process = [dictionary.doc2bow(txt) for txt in corpus]\n",
    "\n",
    "sim_index = WordEmbeddingSimilarityIndex(fasttext_model300,threshold=0.0,exponent=2.0)\n",
    "sim_mat = SparseTermSimilarityMatrix(sim_index, dictionary)\n",
    "\n",
    "ft = {'job_full_resume':[],'fasttext_full_resume':[]}\n",
    "for i in range(1,len(text_process)):\n",
    "    similarity = sim_mat.inner_product(text_process[0], text_process[i], normalized=True)\n",
    "    ft['job_full_resume'].append(job_title[i-1])\n",
    "    ft['fasttext_full_resume'].append(similarity)\n",
    "df_ft_r = pd.DataFrame(ft).sort_values(by='fasttext_full_resume',ascending=False).reset_index(drop=True)\n",
    "# df_ft_r\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116.20438933372498\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "comp_text = [obj_exp] + job_description\n",
    "corpus = [simple_preprocess(txt) for txt in comp_text]\n",
    "dictionary = corpora.Dictionary(corpus)\n",
    "text_process = [dictionary.doc2bow(txt) for txt in corpus]\n",
    "\n",
    "sim_index = WordEmbeddingSimilarityIndex(fasttext_model300,threshold=0.0,exponent=2.0)\n",
    "sim_mat = SparseTermSimilarityMatrix(sim_index, dictionary)\n",
    "\n",
    "ft = {'job':[],'fasttext':[]}\n",
    "for i in range(1,len(text_process)):\n",
    "    similarity = sim_mat.inner_product(text_process[0], text_process[i], normalized=True)\n",
    "    ft['job'].append(job_title[i-1])\n",
    "    ft['fasttext'].append(similarity)\n",
    "df_ft = pd.DataFrame(ft).sort_values(by='fasttext',ascending=False).reset_index(drop=True)\n",
    "# df_ft\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_60327058_e185_11ea_af09_f06e0be3d7d1row0_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_60327058_e185_11ea_af09_f06e0be3d7d1row0_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_60327058_e185_11ea_af09_f06e0be3d7d1row1_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_60327058_e185_11ea_af09_f06e0be3d7d1row1_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_60327058_e185_11ea_af09_f06e0be3d7d1row3_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_60327058_e185_11ea_af09_f06e0be3d7d1row3_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_60327058_e185_11ea_af09_f06e0be3d7d1row4_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_60327058_e185_11ea_af09_f06e0be3d7d1row4_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_60327058_e185_11ea_af09_f06e0be3d7d1row9_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_60327058_e185_11ea_af09_f06e0be3d7d1row9_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }</style><table id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >job_full_resume</th>        <th class=\"col_heading level0 col1\" >fasttext_full_resume</th>        <th class=\"col_heading level0 col2\" >job</th>        <th class=\"col_heading level0 col3\" >fasttext</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row0_col0\" class=\"data row0 col0\" >Data Scientist</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row0_col1\" class=\"data row0 col1\" >0.807631</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row0_col2\" class=\"data row0 col2\" >Data Analyst</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row0_col3\" class=\"data row0 col3\" >0.816074</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row1_col0\" class=\"data row1 col0\" >Data Analyst</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row1_col1\" class=\"data row1 col1\" >0.806549</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row1_col2\" class=\"data row1 col2\" >Data Scientist</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row1_col3\" class=\"data row1 col3\" >0.801971</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row2_col0\" class=\"data row2 col0\" >Fashion Designer</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row2_col1\" class=\"data row2 col1\" >0.725833</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row2_col2\" class=\"data row2 col2\" >Fashion Designer</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row2_col3\" class=\"data row2 col3\" >0.754826</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row3_col0\" class=\"data row3 col0\" >Web Developer</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row3_col1\" class=\"data row3 col1\" >0.712336</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row3_col2\" class=\"data row3 col2\" >Public Relations Coordinator</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row3_col3\" class=\"data row3 col3\" >0.746612</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row4_col0\" class=\"data row4 col0\" >Public Relations Coordinator</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row4_col1\" class=\"data row4 col1\" >0.711472</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row4_col2\" class=\"data row4 col2\" >Web Developer</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row4_col3\" class=\"data row4 col3\" >0.741048</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row5_col0\" class=\"data row5 col0\" >Financial Analyst</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row5_col1\" class=\"data row5 col1\" >0.701069</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row5_col2\" class=\"data row5 col2\" >Financial Analyst</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row5_col3\" class=\"data row5 col3\" >0.737920</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row6_col0\" class=\"data row6 col0\" >Customer Service Assistant</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row6_col1\" class=\"data row6 col1\" >0.698429</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row6_col2\" class=\"data row6 col2\" >Customer Service Assistant</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row6_col3\" class=\"data row6 col3\" >0.730869</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row7_col0\" class=\"data row7 col0\" >Social Media Marketing Specialist</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row7_col1\" class=\"data row7 col1\" >0.691323</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row7_col2\" class=\"data row7 col2\" >Social Media Marketing Specialist</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row7_col3\" class=\"data row7 col3\" >0.725095</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row8_col0\" class=\"data row8 col0\" >Business Development Specialist</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row8_col1\" class=\"data row8 col1\" >0.689053</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row8_col2\" class=\"data row8 col2\" >Business Development Specialist</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row8_col3\" class=\"data row8 col3\" >0.724723</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row9_col0\" class=\"data row9 col0\" >User Experience (UX) Designer</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row9_col1\" class=\"data row9 col1\" >0.688049</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row9_col2\" class=\"data row9 col2\" >Business Analyst</td>\n",
       "                        <td id=\"T_60327058_e185_11ea_af09_f06e0be3d7d1row9_col3\" class=\"data row9 col3\" >0.715563</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x148c3995508>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp = pd.concat([df_ft_r,df_ft],axis=1).head(10)\n",
    "comp.style.apply(color_diff,axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>4.4.2 Word2Vec 300</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import TfidfModel\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46571874618530273 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "comp_text = [res] + job_description\n",
    "corpus = [simple_preprocess(txt) for txt in comp_text]\n",
    "dictionary = corpora.Dictionary(corpus)\n",
    "text_process = [dictionary.doc2bow(txt) for txt in corpus]\n",
    "\n",
    "tfidf = TfidfModel(dictionary=dictionary)\n",
    "w2v = Word2Vec(corpus, min_count=5, size=300, seed=12345)\n",
    "sim_index = WordEmbeddingSimilarityIndex(w2v.wv,threshold=0.0,exponent=2.0)\n",
    "sim_mat = SparseTermSimilarityMatrix(sim_index, dictionary,\n",
    "                                     tfidf,\n",
    "                                     nonzero_limit=100)\n",
    "\n",
    "wvec = {'job_full_resume':[],'word2vec_full_resume':[]}\n",
    "for i in range(1,len(text_process)):\n",
    "    similarity = sim_mat.inner_product(text_process[0], text_process[i], normalized=True)\n",
    "    wvec['job_full_resume'].append(job_title[i-1])\n",
    "    wvec['word2vec_full_resume'].append(similarity)\n",
    "df_wvec_r = pd.DataFrame(wvec).sort_values(by='word2vec_full_resume',ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(time.time()-t,'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35205769538879395 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "comp_text = [obj_exp] + job_description\n",
    "corpus = [preprocess(txt) for txt in comp_text]\n",
    "dictionary = corpora.Dictionary(corpus)\n",
    "text_process = [dictionary.doc2bow(txt) for txt in corpus]\n",
    "\n",
    "tfidf = TfidfModel(dictionary=dictionary)\n",
    "w2v = Word2Vec(corpus, min_count=5, size=300, seed=12345)\n",
    "sim_index = WordEmbeddingSimilarityIndex(w2v.wv,threshold=0.0,exponent=2.0)\n",
    "sim_mat = SparseTermSimilarityMatrix(sim_index, dictionary,\n",
    "                                     tfidf,\n",
    "                                     nonzero_limit=100)\n",
    "\n",
    "wvec = {'job':[],'word2vec':[]}\n",
    "for i in range(1,len(text_process)):\n",
    "    similarity = sim_mat.inner_product(text_process[0], text_process[i], normalized=True)\n",
    "    wvec['job'].append(job_title[i-1])\n",
    "    wvec['word2vec'].append(similarity)\n",
    "df_wvec = pd.DataFrame(wvec).sort_values(by='word2vec',ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(time.time()-t,'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row0_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row0_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row1_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row1_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row2_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row2_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row3_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row3_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row4_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row4_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row5_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row5_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row6_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row6_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row7_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row7_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row8_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row8_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row9_col0 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }    #T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row9_col2 {\n",
       "            background-color:  #bbe6ed;\n",
       "        }</style><table id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >job_full_resume</th>        <th class=\"col_heading level0 col1\" >word2vec_full_resume</th>        <th class=\"col_heading level0 col2\" >job</th>        <th class=\"col_heading level0 col3\" >word2vec</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row0_col0\" class=\"data row0 col0\" >Project Manager</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row0_col1\" class=\"data row0 col1\" >1.000000</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row0_col2\" class=\"data row0 col2\" >Data Scientist</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row0_col3\" class=\"data row0 col3\" >0.492003</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row1_col0\" class=\"data row1 col0\" >User Experience (UX) Designer</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row1_col1\" class=\"data row1 col1\" >0.996804</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row1_col2\" class=\"data row1 col2\" >Data Analyst</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row1_col3\" class=\"data row1 col3\" >0.465435</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row2_col0\" class=\"data row2 col0\" >Industrial Engineer</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row2_col1\" class=\"data row2 col1\" >0.988154</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row2_col2\" class=\"data row2 col2\" >Web Developer</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row2_col3\" class=\"data row2 col3\" >0.240611</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row3_col0\" class=\"data row3 col0\" >Fashion Designer</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row3_col1\" class=\"data row3 col1\" >0.982716</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row3_col2\" class=\"data row3 col2\" >Business Analyst</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row3_col3\" class=\"data row3 col3\" >0.234503</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row4_col0\" class=\"data row4 col0\" >Data Analyst</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row4_col1\" class=\"data row4 col1\" >0.980658</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row4_col2\" class=\"data row4 col2\" >User Experience (UX) Designer</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row4_col3\" class=\"data row4 col3\" >0.233998</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row5_col0\" class=\"data row5 col0\" >Business Analyst</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row5_col1\" class=\"data row5 col1\" >0.976606</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row5_col2\" class=\"data row5 col2\" >Business Consultant</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row5_col3\" class=\"data row5 col3\" >0.218563</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row6_col0\" class=\"data row6 col0\" >Customer Service Assistant</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row6_col1\" class=\"data row6 col1\" >0.975129</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row6_col2\" class=\"data row6 col2\" >Fashion Designer</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row6_col3\" class=\"data row6 col3\" >0.212155</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row7_col0\" class=\"data row7 col0\" >Web Developer</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row7_col1\" class=\"data row7 col1\" >0.974559</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row7_col2\" class=\"data row7 col2\" >Computer Programmer</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row7_col3\" class=\"data row7 col3\" >0.209471</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row8_col0\" class=\"data row8 col0\" >Business Development Specialist</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row8_col1\" class=\"data row8 col1\" >0.974496</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row8_col2\" class=\"data row8 col2\" >Graphic Designer</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row8_col3\" class=\"data row8 col3\" >0.204347</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row9_col0\" class=\"data row9 col0\" >Graphic Designer</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row9_col1\" class=\"data row9 col1\" >0.971739</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row9_col2\" class=\"data row9 col2\" >Social Media Marketing Specialist</td>\n",
       "                        <td id=\"T_cdb0b15c_e185_11ea_94e6_f06e0be3d7d1row9_col3\" class=\"data row9 col3\" >0.203323</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x148c38f6208>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp = pd.concat([df_wvec_r,df_wvec],axis=1).head(10)\n",
    "comp.style.apply(color_diff,axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"we are looking for an outstanding web developer who is responsible for designing, coding and modifying websites, from layout to function. the successful candidate should strive to create visually appealing sites that feature user-friendly design and clear navigation. essential duties and responsibilities includes: write well designed, testable, efficient code by using best software development practices create website layout/user interface by using standard html/css practices integrate data from various back-end services and databases gather and refine specifications and requirements based on technical needs create and maintain software documentation be responsible for maintaining, expanding, and scaling our site cooperate with graphic designer to match visual design intent important skills/traits: general web functions and standards. experience in planning and delivering software platforms top-notchprogramming skills and in-depth knowledge of web applications and programming languages such as html, css, javascript, jquery and api's functional knowledge or hands on design experience with web services (rest, soap, etc.) is needed to be successful in this position bs in computer science or a related field   \""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_no_title['Web Developer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>count_vectorizer</th>\n",
       "      <th>job</th>\n",
       "      <th>tfidf_vectorizer</th>\n",
       "      <th>job</th>\n",
       "      <th>glove</th>\n",
       "      <th>job</th>\n",
       "      <th>fasttext</th>\n",
       "      <th>job</th>\n",
       "      <th>word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.477106</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.321460</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.979959</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>0.816074</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.492003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>0.424797</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>0.279848</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>0.973099</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.801971</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>0.465435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User Experience (UX) Designer</td>\n",
       "      <td>0.189792</td>\n",
       "      <td>Web Developer</td>\n",
       "      <td>0.113473</td>\n",
       "      <td>Computer Programmer</td>\n",
       "      <td>0.971956</td>\n",
       "      <td>Fashion Designer</td>\n",
       "      <td>0.754826</td>\n",
       "      <td>Web Developer</td>\n",
       "      <td>0.240611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Web Developer</td>\n",
       "      <td>0.189388</td>\n",
       "      <td>User Experience (UX) Designer</td>\n",
       "      <td>0.108392</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>0.964259</td>\n",
       "      <td>Public Relations Coordinator</td>\n",
       "      <td>0.746612</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>0.234503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>0.154842</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>0.090215</td>\n",
       "      <td>Web Developer</td>\n",
       "      <td>0.961016</td>\n",
       "      <td>Web Developer</td>\n",
       "      <td>0.741048</td>\n",
       "      <td>User Experience (UX) Designer</td>\n",
       "      <td>0.233998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Computer Programmer</td>\n",
       "      <td>0.148704</td>\n",
       "      <td>Computer Programmer</td>\n",
       "      <td>0.087828</td>\n",
       "      <td>User Experience (UX) Designer</td>\n",
       "      <td>0.960939</td>\n",
       "      <td>Financial Analyst</td>\n",
       "      <td>0.737920</td>\n",
       "      <td>Business Consultant</td>\n",
       "      <td>0.218563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fashion Designer</td>\n",
       "      <td>0.144647</td>\n",
       "      <td>Fashion Designer</td>\n",
       "      <td>0.086567</td>\n",
       "      <td>Industrial Engineer</td>\n",
       "      <td>0.949891</td>\n",
       "      <td>Customer Service Assistant</td>\n",
       "      <td>0.730869</td>\n",
       "      <td>Fashion Designer</td>\n",
       "      <td>0.212155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Graphic Designer</td>\n",
       "      <td>0.143778</td>\n",
       "      <td>Graphic Designer</td>\n",
       "      <td>0.084952</td>\n",
       "      <td>Social Media Marketing Specialist</td>\n",
       "      <td>0.949283</td>\n",
       "      <td>Social Media Marketing Specialist</td>\n",
       "      <td>0.725095</td>\n",
       "      <td>Computer Programmer</td>\n",
       "      <td>0.209471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Consultant</td>\n",
       "      <td>0.134100</td>\n",
       "      <td>Social Media Marketing Specialist</td>\n",
       "      <td>0.077067</td>\n",
       "      <td>Graphic Designer</td>\n",
       "      <td>0.949175</td>\n",
       "      <td>Business Development Specialist</td>\n",
       "      <td>0.724723</td>\n",
       "      <td>Graphic Designer</td>\n",
       "      <td>0.204347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Social Media Marketing Specialist</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>0.076817</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>0.938822</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>0.715563</td>\n",
       "      <td>Social Media Marketing Specialist</td>\n",
       "      <td>0.203323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 job  count_vectorizer  \\\n",
       "0                     Data Scientist          0.477106   \n",
       "1                       Data Analyst          0.424797   \n",
       "2      User Experience (UX) Designer          0.189792   \n",
       "3                      Web Developer          0.189388   \n",
       "4                   Business Analyst          0.154842   \n",
       "5                Computer Programmer          0.148704   \n",
       "6                   Fashion Designer          0.144647   \n",
       "7                   Graphic Designer          0.143778   \n",
       "8                Business Consultant          0.134100   \n",
       "9  Social Media Marketing Specialist          0.129412   \n",
       "\n",
       "                                 job  tfidf_vectorizer  \\\n",
       "0                     Data Scientist          0.321460   \n",
       "1                       Data Analyst          0.279848   \n",
       "2                      Web Developer          0.113473   \n",
       "3      User Experience (UX) Designer          0.108392   \n",
       "4                   Business Analyst          0.090215   \n",
       "5                Computer Programmer          0.087828   \n",
       "6                   Fashion Designer          0.086567   \n",
       "7                   Graphic Designer          0.084952   \n",
       "8  Social Media Marketing Specialist          0.077067   \n",
       "9                    Project Manager          0.076817   \n",
       "\n",
       "                                 job     glove  \\\n",
       "0                     Data Scientist  0.979959   \n",
       "1                       Data Analyst  0.973099   \n",
       "2                Computer Programmer  0.971956   \n",
       "3                   Business Analyst  0.964259   \n",
       "4                      Web Developer  0.961016   \n",
       "5      User Experience (UX) Designer  0.960939   \n",
       "6                Industrial Engineer  0.949891   \n",
       "7  Social Media Marketing Specialist  0.949283   \n",
       "8                   Graphic Designer  0.949175   \n",
       "9                    Project Manager  0.938822   \n",
       "\n",
       "                                 job  fasttext  \\\n",
       "0                       Data Analyst  0.816074   \n",
       "1                     Data Scientist  0.801971   \n",
       "2                   Fashion Designer  0.754826   \n",
       "3       Public Relations Coordinator  0.746612   \n",
       "4                      Web Developer  0.741048   \n",
       "5                  Financial Analyst  0.737920   \n",
       "6         Customer Service Assistant  0.730869   \n",
       "7  Social Media Marketing Specialist  0.725095   \n",
       "8    Business Development Specialist  0.724723   \n",
       "9                   Business Analyst  0.715563   \n",
       "\n",
       "                                 job  word2vec  \n",
       "0                     Data Scientist  0.492003  \n",
       "1                       Data Analyst  0.465435  \n",
       "2                      Web Developer  0.240611  \n",
       "3                   Business Analyst  0.234503  \n",
       "4      User Experience (UX) Designer  0.233998  \n",
       "5                Business Consultant  0.218563  \n",
       "6                   Fashion Designer  0.212155  \n",
       "7                Computer Programmer  0.209471  \n",
       "8                   Graphic Designer  0.204347  \n",
       "9  Social Media Marketing Specialist  0.203323  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df_cv,df_tv,df_glove,df_ft,df_wvec],axis=1).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 4. Skill Match</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_skills = resume.extract_skills(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jobs_no_title' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-f70735142c57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mskill_match\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'job'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'skill_match'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjobs_no_title\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mskills\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresume\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_skills\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcommon_skills\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_skills\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskills\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'jobs_no_title' is not defined"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "skill_match = {'job':[], 'skill_match':[]}\n",
    "for (job, description) in jobs_no_title.items():\n",
    "    skills = resume.extract_skills(description)\n",
    "    common_skills = list(set(res_skills) & set(skills))\n",
    "    percent_skills = len(common_skills) / len(res_skills)\n",
    "    skill_match['job'].append(job)\n",
    "    skill_match['skill_match'].append(percent_skills)\n",
    "\n",
    "df_skill = pd.DataFrame(skill_match).sort_values(by='skill_match',ascending=False).reset_index(drop=True)\n",
    "print(time.time()-t,'seconds')\n",
    "df_skill.skill_match = df_skill.skill_match / df_skill.skill_match.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skill_score(skills):\n",
    "    skills = skills.split('|')\n",
    "    common_skills = list(set(res_skills) & set(skills))\n",
    "    percent_skills = len(common_skills) / len(res_skills)\n",
    "    return percent_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_wvec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-97a42e819d38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_merge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_wvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_skill\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_merge\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf_merge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2vec\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdf_merge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mskill_match\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf_merge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_wvec' is not defined"
     ]
    }
   ],
   "source": [
    "df_merge = df_wvec.set_index('job').join(df_skill.set_index('job'))\n",
    "df_merge['score'] = (df_merge.word2vec + df_merge.skill_match) / 2\n",
    "df_merge.sort_values(by='score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4451432228088379 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "comp_text = [obj_exp] + job_dict['description']\n",
    "corpus = [preprocess(txt) for txt in comp_text]\n",
    "dictionary = corpora.Dictionary(corpus)\n",
    "text_process = [dictionary.doc2bow(txt) for txt in corpus]\n",
    "\n",
    "tfidf = TfidfModel(dictionary=dictionary)\n",
    "w2v = Word2Vec(corpus, min_count=5, size=300, seed=12345)\n",
    "sim_index = WordEmbeddingSimilarityIndex(w2v.wv,threshold=0.0,exponent=2.0)\n",
    "sim_mat = SparseTermSimilarityMatrix(sim_index, dictionary,\n",
    "                                     tfidf,\n",
    "                                     nonzero_limit=100)\n",
    "\n",
    "wvec = {'job':[],'word2vec':[],'company':[],'description':[],'skills':[],'skill_score':[]}\n",
    "for i in range(0,len(job_dict['title'])):\n",
    "    similarity = sim_mat.inner_product(text_process[0], text_process[i+1], normalized=True)\n",
    "    wvec['job'].append(job_dict['title'][i])\n",
    "    wvec['word2vec'].append(similarity)\n",
    "    wvec['company'].append(job_dict['company'][i])\n",
    "    wvec['description'].append(job_dict['description'][i])\n",
    "    wvec['skills'].append(job_dict['skills'][i])\n",
    "    wvec['skill_score'].append(skill_score(job_dict['skills'][i]))\n",
    "df_wvec = pd.DataFrame(wvec).sort_values(by='word2vec',ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(time.time()-t,'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job = pd.DataFrame(job_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data Scientist\n",
      "ROBERT SMITH\n",
      "\n",
      "Phone: (123) 456 78 99 \n",
      "Email: info@qwikresume.com\n",
      "Website: www.qwikresume.com\n",
      "LinkedIn:\n",
      "linkedin.com/qwikresume\n",
      "Address: 1737 Marshville Road,\n",
      "Alabama.\n",
      "\n",
      "Objective\n",
      "Data Scientist with PhD in Physics and 1+ industrial experience. Two years of working experience \n",
      "in Data Analysis team of LIGO Scientific Collaboration [$3M Special Breakthrough Prize winner of \n",
      "2016]. Over ten years of successful research experience in both theoretical and computational \n",
      "physics. Strong problem-solving and analytical skills. Advanced programming proficiency. Certified\n",
      "in Data Analysis and Machine Learning.\n",
      "Skills\n",
      "\n",
      "Data Mining, Data Analysis, Machine Learning, Python, R, MATLAB, Sphinx, LaTeX, Mathematica, \n",
      "Maple, GIT, CVS, HTCondor.\n",
      "Work Experience\n",
      "Data Scientist\n",
      "ABC Corporation ­ May 1994 – May 2005 \n",
      " Assisted in determining client needs, deliverable design, estimates and feasibility for \n",
      "\n",
      "analytical projects concerning a custom study for a manufacturer who is using the results to \n",
      "support a litigation claim.\n",
      "\n",
      " Served as an internal resource for Jacknife programming and documentation.\n",
      " Designed and developed small scale deliverables related to the custom study.\n",
      " Participated in the Post Project Review QIP team.\n",
      " Responsible for results reporting in the appropriate media and creation of supporting \n",
      " Monitored products from statistical programs for accuracy, consistency and statistical validity.\n",
      " Designed and applied statistical and mathematical methods for corporate analytics that were \n",
      "\n",
      "documentation for the client.\n",
      "\n",
      "implemented into client-facing products.\n",
      "\n",
      "Data Scientist\n",
      "ABC Corporation ­ 1993 – 1994 \n",
      " Maintained automated ETL for reporting.\n",
      "\n",
      "\n",
      "Implemented Data mining and machine learning algorithms to describe and predict user \n",
      "behavior on various retailer websites.\n",
      "I revamped their &quot;Predictive Marketing&quot; process to be more data driven and \n",
      "profitable.\n",
      "increase in conversion.\n",
      "\n",
      "\n",
      " The new process was able to hone in on more useful user segments that had a significant \n",
      " Skills Used Data Cleansing and Data Analysis using Python, Scala, R and Spark.\n",
      " Cloud computing on AWS.\n",
      " Automation of reporting..\n",
      "\n",
      "Education\n",
      "\n",
      "© This Free Resume Template is the copyright of Qwikresume.com. Usage\n",
      "\n",
      "Guidelines\n",
      "\n",
      "\f",
      " Bachelor Of Science - (Stanford)\n",
      "\n",
      "© This Free Resume Template is the copyright of Qwikresume.com. Usage\n",
      "\n",
      "Guidelines\n",
      "\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overview southern california based karma is more than just a car company although we are best known as a creator of soul stirring luxury electric vehicles  karma has emerged as a high tech incubator offering innovators a perfect platform to prove their emerging technologies every revero is designed at our headquarters in irvine and created with great individual care and world class craftsmanship at the karma innovation and customization center in moreno valley  ca the data scientist reporting to the manager  data sciences and innovation  is responsible for data collection analyze  extract  normalize  and label relevant data from multiple sources to provide interpretation and visualizations reports around key data driven projects responsibilities design and build new data set processes for modeling  data mining  and production purposes determine new ways to improve data and search quality  and predictive capabilities perform and interpret data studies and product experiments concerning new data sources or new uses for existing data sources develop prototypes  proof of concepts  algorithms  predictive models  and custom analysis create visualizations and reports to show insights obtained from data mining efforts interact with multiple internal and external sources in support of ongoing and proof of concept projects ensure timely  accurate and credible information is provided and interpreted and distilled into action driven information for diverse audiences attend trade shows  conferences and learning opportunity to familiarize with the industry leading trends in data sciences and predictive analytics to help drive karma s data sciences and technology department development other duties  as assigned\n",
      "----------------------------------------\n",
      "lead data scientist   engineer   aliso viejo  ca awm smart shelf is reinventing retail and looking for smart  talented people to help build on our current and future data and analytics platforms  pipelines  and machine learning models our solutions encompass a wide range of data such as real time computer vision and deep learning that enables an understanding of what shoppers and workers are doing  e g movement  actions  product selection  etc awm frictionless  shopping  cashierless checkout demographic data captured via anonymous facial analysis ads video playback and effectiveness product placement and pricing the ideal candidate will have the ability to use modern techniques to understand and interpret data  reaching meaningful conclusions based on solid premises predict optimizations both in real time and via big data processing handle large and rapidly growing data sets job duties contributing to the development and maintenance of data pipelines as well as creation of new ones based on ai computer vision and other data sources validation of ai models and big data analysis performing ad hoc analysis on proprietary datasets for internal and external stakeholders annotating proprietary datasets and giving direction to data labelers performing exploratory analysis on data to find trends training and evaluating various machine learning models\n",
      "----------------------------------------\n",
      "lifesprk s product and engineering team is growing we are having great success building custom solutions for our teammates in order to bring to light the first ever life experience alternative delivery system  leads our focus  and our passion  is lifecare  not just healthcare come join us and be part of building something truly meaningful from the ground up with a diverse team of committed  humble  awesome people all fully distributed from anywhere in the country lifesprk  headquartered in minneapolis  with our head of engineering in boulder colorado   has been sparking lives for    years and it is time to take our  whole person senior care  model to a greater and greater reach and to do that  we need you to come and build the  best in class  platform for whole person health as our most senior data scientist you will provider leadership across our data science and analytics efforts with your expertise we will create predictive insights to support leads in this new role  you will be laying the foundations of how we unlock the insights hidden within all our data you will help to define our strategies around data governance  security  analysis and ai ml you will bring your passion for how data can transform lives this hands on role will require the development of solid processes around data acquisition  analysis and life cycle management have your favorite toolset we would love to hear about how you have done this in the past this role requires excellent communication skills  you will be our master storyteller as you identify new business questions  develop analytical methods to answer those questions and conduct experiments to validate our assumptions all while being hyper focused on quality outcomes for our members come use your superpowers for good and join us in sparking lives how you will spend your days building a collaborative and service oriented data and analytics discipline that empowers subject matter experts with data and tools throughout the organization delivering and supporting the delivery of retroactive analysis in order to provide deeper understanding of the leads initiatives designing the system architecture for the data and analytics environment to ensure data quality system stability and extensibility scalability maintainability collaborating with data engineering team to develop a comprehensive data architecture building and testing predictive models that increase leads efficacy presenting compelling reports that support the business with powerful stories and statistically sound analysis leveling up all those around you in how to think about data and analysis\n",
      "----------------------------------------\n",
      "key responsibilities data science focusing on the aspect of applying machine learning and ai capabilities to the clinical research function at the company this position will not only expose you to the emerging demand and growth of ml and ai in healthcare but allow you to experience and take part in its development the data scientist will work directly with the principal data scientist in the business excellence ai group the primary focus will be to assist the principal data scientist to embark on various ml and ai projects that hinge on the prospect of solving challenging business problems projects are ranging from creating data driven dashboards to building complex prediction models  image detection processing  and developing natural language processing capabilities conduct advanced research and engineering for machine learning  ml  and nlp solutions for healthcare related topics work with large scale healthcare datasets to develop and test your ml and nlp models take advantage of models developed internally and available from the community to solve research problems in healthcare work closely with the ai research team as well as the clinical team to transfer your proof of concept research prototypes into meaningful features within our products skills knowledge of python and sql required knowledge of bi preferred knowledge of tableau preferred hands on experience with data pre processing  modeling  and visualization proficient in python hands on experience with sql and nosql databases knowledge of machine learning libraries  scikit learn  tensorflow  and pytorch prior experience in working with tableau and or power bi good communication and team working skills experience of working with aws is a plus education  amp  experience\n",
      "----------------------------------------\n",
      "we are looking for a data scientist who will support our product  sales  leadership and marketing teams with insights gained from analyzing company data the ideal candidate will be intricately involved in running analytical experiments in a methodical manner and will regularly evaluate alternate models via theoretical approaches they must have a proven ability to drive business results with their data based insights primary responsibilities understanding data flow in a large  distributed system designing  coding and executing data investigations performing robust statistical analyses producing internal presentations  customer reports and visualizations to summarize the conclusions handle a diverse set of problems ranging from probabilistic interference on phone trajectories  data fusion between noisy sensors  modeling and classification of driving behavior  and data visualization all other duties as assigned\n",
      "----------------------------------------\n",
      "this nationwide mortgage industry leader has an immediate full time opportunity in santa ana  ca for a senior data analyst with deep mortgage banking experience will be responsible for quantitative and data analysis across mortgage banking activities   research  develop and build analysis data sets to support sales and operations management team responsibilities include developing sql queries stored procedures to retrieve and analyze data to support digitization researching to identify underlying root cause for issues using data building dashboards to continuously monitor implemented solutions coordinating with operation management to gather suggestions for improvements performing ad hoc analytical requests and research projects for internal parties providing feedback to senior management for identified problem areas and providing proactive solutions this position requires years experience as a data analyst within the mortgage banking industry proficient in the manipulation and use of large and complex databases strong understanding of sql database and data warehouse concepts and structures strong quantitative skills with a proven ability to translate analysis into meaningful insights proficient in sql  power bi and ms office products  excel  word  powerpoint including pivot  graph and slicer techniques ability to create  compose and edit written materials and presentations excellent verbal  written and interpersonal communication skills\n",
      "----------------------------------------\n",
      "senior financial data analyst w healthcare economics background this is an excellent opportunity for a candidate that is looking to take their career to the next level and come in on the ground floor in a fast moving  dynamic company the position is broad and will be exposed to all aspects of operations great opportunity for someone to broaden their skill set and get exposure to a very sophisticated  technology driven healthcare company job description the sr  financial data analyst will review  analyze  and report on data from the company s reporting system which includes medical claims data  utilization data  pharmacy data  and other sources such as gl and accounting related entries this person will be responsible for creating adhoc reports and models to support the analysis of product line profitability  gross margin  and possible market expansion opportunities there will also be significant involvement in working cross functionally with departments  so great communication skills are key for success in this role job duties reconcile and verify the integrity of yearly and monthly financial data to the general ledger work with the fp amp a team to incorporate budget data and assumptions into the company s reporting system validate the integrity of claim payment and analyze contract rate trending impact and anomalies validate and reconcile key authorization admit and bed day metrics to actual paid claim data support regional vp s in providing analysis of monthly data and ad hoc reporting of key performance indicators support finance and operations in developing predictive kpi s to better forecast and manage the business work with all levels of staff to direct  assist  and explain financial analysis processes read and interpret contracts with regards to risk pool definitions for revenue  expense  carve outs and calculations update risk pool calculations and definitions for newly delegated entities  as well as contract amendments for existing entities analyze key drivers of risk pool surplus or deficits and communicate to appropriate internal parties\n",
      "----------------------------------------\n",
      "summary our organization is implementing sap business one the position is the lead for collecting source master data  managing the data clean up  and migration to sap b  templates customizing and maintaining sap b   writing reports  and providing user support candidate should have experience working with erp systems for small and midsize enterprises  preferably sap business one this role requires the candidate to support our internal business systems and processes  including basic it functions experience with sql  microsoft excel and reporting required this is a full time  on site role essential functions collecting source master data from legacy systems and spreadsheets master data cleansing and transformation for migration templates to sap business one analyses  data validation  data mining master data gatekeeper process set up understand and optimize utilization of sap b  workflows collaborate with sap partner support to resolve problems and improve processes in sap implement systems  technologies  and processes to grow and expand the effectiveness of the systems review data  test  and implementation in sandbox environment and migrate to production environment validate the inputs  quantities  units of measure  outputs and any associated key data attributes as they create full product recipes and overall production data workflows maintain data integrity in systems by running queries and analyzing data create  document  maintain  and support a variety of reports and queries develop user procedures  guidelines  and documentation train new system users on new processes and functionality creating and building bill of materials  bom  in sap business one to support supply chain and operations teams perform additional tasks as needed competencies  desire to grow and learn new skills  positive attitude  take responsibility  self confident  controls emotions  effective communicator  gives their absolute best  respectful  team orientated\n",
      "----------------------------------------\n",
      "this is us we have a bold vision to connect    million vehicles by our customers come first we lead through innovation we win as one we act with integrity we adhere to our brand promise   to make the complex simple  the future predictable  and our customers successful with nearly   million connected vehicles today spireon is an exciting player in the growing connected car and internet of things  iot  technology categories we help people and businesses track and protect their most important assets with vehicle intelligence solutions that gather big data and provide the critical insights with easy to use dashboards and apps this is you we are looking for a data scientist  machine learning engineer to design and build convolutional neural networks for smart sensors spireon develops computer vision based smart sensors to detect environment and reports for the transportation sector as a machine learning engineer  you will implement cnn algorithms to run on smart sensors   you must be able to work across multiple teams to ensure project objectives are met responsibilities design and develop algorithms for challenging vision classification and detections problems research and develop statistical learning models for data analysis implementation of computer vision and ml algorithms collect data and analyze real world data deploy ml systems  inference at the edge   monitor metrics prototyping ml algorithms collaborate with product management and engineering departments to understand company needs and devise possible solutions keep up to date with latest technology trends communicate results and ideas to key decision makers\n",
      "----------------------------------------\n",
      "worker sub type regular job description the position we are seeking a data scientist to help develop state of the art machine learning techniques to solve long standing problems in computer security we discover novel ml techniques and applications  build systems to handle petabytes of ludicrously high dimensional data  and protect people from bad guys with machine learning at the heart blackberry protect  the data science team is a critical  highly visible  and high impact team within the company the team brings together experts from machine learning  stats  computer science  computer security  and various applied sciences  with backgrounds including deep learning  bayesian statistics  time series modeling  topology  scalable data processing  and software engineering you don t need prior experience in security  although it helps the right candidate will be able to gain domain expertise on the job  surrounded by some of the computer security industry s leading minds however  for this particular hire  we do require the candidate to have significant deep learning expertise what you will do invent novel machine learning techniques to solve important problems in computer security improve upon existing machine learning techniques discover ways to strengthen machine learning models against adversarial attacks write code that scales to very large datasets  often with millions of dimensions collaborate closely with internal product and engineering teams to help turn ml research prototypes into new products or features publish papers and present research at conferences  including ml ai stats conferences  as well as security conferences like black hat  defcon  and rsa stay abreast of the latest publications and state of the art techniques in relevant research communities  e g   ml and stats consult with other teams on applications of data science collaborate with other data scientists on the team to help accomplish all of the above\n",
      "----------------------------------------\n",
      "job description  designs  develops and programs methods  processes  and systems to consolidate and analyze unstructured  diverse  big data  sources to generate actionable insights and solutions for client services and product enhancement constructs forecasts and advance modeling to recommend strategic tactical plans based on business data and market knowledge interacts with product and service teams to identify questions and issues for data analysis and experiments develops and codes software programs  algorithms and automated processes to cleanse  integrate and evaluate large datasets from multiple disparate sources identifies meaningful insights from large data and metadata sources  interprets and communicates insights and findings from analysis and experiments to product  service  and business managers job duties operational excellence design and deployment of models  quantitative analysis and design queries for all clients and internal teams leverages existing bi reporting and analysis packages to extend incremental value and business intelligence capabilities develops and disseminates reports and forecasts to recommend strategic   tactical plans based on business data and market knowledge  communicates findings from analysis to inform action works within interdisciplinary teams across complex issues of diverse scope where analysis of situation or data requires evaluation of a variety of factors  including an understanding of current business trends and overall market context applies business intelligence tools and processes to enable design and deployment of consistent processes and systems to enable cross functional strategy deployment across the organization products services conducts analysis utilizing business intelligence methods and approaches in support of products necessary for critical expansion of services  including care management  virtual care  targeted clinical programming  and related services insures business intelligence integration for technology implementation for each health center according to xo established product parameters to enable operational processes\n",
      "----------------------------------------\n",
      "loandepot  america s lender  matches borrowers through technology and high touch customer care with the credit they need to fuel their lives while there are many loan touch career opportunities within loandepot  we could not take care of our employees  nor our customers  without the amazing support of our corporate teams from hr  amp  marketing to finance  amp  compliance   teamloandepot is always searching for the best talent out there with over      billion in funded loans since inception  the evolution  amp  enthusiasm is not slowing down anytime soon come join us loandepot   we are america s lender position summary responsible for overseeing the ingestion  analysis and reporting of voice of the customer data  metrics and information helps to deliver high quality and timely information in support of a wide range of initiatives including operation control  performance improvement  compliance  regulatory reporting  and all other organizational strategies ensures the performance of all duties in accordance with the company s policies and procedures  all u s  state and federal laws and regulations  wherein the company operates responsibilities analyzes said data in real time and creates feedback loops for emerging  high priority issues and findings assists with improving the way in which data and information is ingested by the department creates departmental reporting  including analysis  and shares findings with management responsible for assisting with department audits  identifying trends  and determining system improvements\n",
      "----------------------------------------\n",
      "important notes this position is fully remote for the duration of covid    with an eventual return to our orange county office we are only considering local candidates we are not working with third parties at this time  any resumes from vendors will result in removal from our vendor list we are unable to provide sponsorship at this time verys is a multi disciplined technology delivery firm that offers a strategic approach to building software through user centered design  modern development architecture  business alignment all wrapped up in a structured agile environment we build software to be proud of for clients like blizzard  american airlines  kia  and experian right now  we re looking to welcome a new machine learning architect to join our team in orange county  ca in this role  you will work alongside technical leads  developers  qa analysts  and project managers to deliver the quality code that s lead to our stable growth over the last   years if you are excited by solving complex challenges and growing your career within an innovative software services company  we d love to hear from you what you will be doing extract data from a database  cleaning the data  and preparing it for consumption select the best algorithmic approach to serve an ml use case tune the model for development construct data pipelines to maintain the model monitor the model for performance and drift\n",
      "----------------------------------------\n",
      "important notes this position is fully remote for the duration of covid    with an eventual return to our orange county office we are only considering local candidates we are not working with third parties at this time  any resumes from vendors will result in removal from our vendor list we are unable to provide sponsorship at this time verys is a multi disciplined technology delivery firm that offers a strategic approach to building software through user centered design  modern development architecture  business alignment all wrapped up in a structured agile environment we build software to be proud of for clients like blizzard  american airlines  kia  and experian right now  we re looking to welcome a new machine learning architect to join our team in orange county  ca in this role  you will work alongside technical leads  developers  qa analysts  and project managers to deliver the quality code that s lead to our stable growth over the last   years if you are excited by solving complex challenges and growing your career within an innovative software services company  we d love to hear from you what you will be doing extract data from a database  cleaning the data  and preparing it for consumption select the best algorithmic approach to serve an ml use case tune the model for development construct data pipelines to maintain the model monitor the model for performance and drift\n",
      "----------------------------------------\n",
      "who we are ncsoft is a premiere digital entertainment company and global publisher with worldwide locations and more than       employees focused on bringing extraordinary games to life for millions of fans around the world established in      and headquartered in seoul  south korea  we quickly became a key leader in online games best known for critically acclaimed franchises including lineage  aion  guild wars  and blade  amp  soul  ncsoft is also one of the world s top mobile developers with lineage  m occupying the    grossing revenue slot on google play our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same we are looking for a data scientist to join our fraud and game surveillance unit and help us keep our games safe and fun for all our players we are looking for someone with a burning curiosity about our players and our games  someone who can go deep to find answers and bring back actionable insights the ideal candidate is equally passionate about machine learning and improving the player experience this role will partner closely with design  engineering  and customer service to help create and maintain a safe and welcoming environment for all our players you will help build tools to detect toxic chat and sift pvp match records to find cheats and bots this is your chance to help make our games safer  friendlier  and more fun why join the customer care team you are a passionate gamer  you will join us in supporting multiple aaa titles we are all gamers and we love helping our fellow players you enjoy creating positive user experiences this is at the core of what we do you think about how we best prevent players from having to contact us and how to make their interactions with our team seamless you learn from negative feedback and get satisfaction from positive outcomes you love a challenge you will encounter daily opportunities to overcome new challenges and problems you thrive in a fast pasted  high volume work environment you love to share your knowledge and experience  we know our games and our player base inside and out and we leverage that knowledge to drive improvement you are good at finding ways to best impart your knowledge to internal teams and our customers\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for desc in df_wvec['description']:\n",
    "    print(desc)\n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>word2vec</th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>skills</th>\n",
       "      <th>skill_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.493377</td>\n",
       "      <td>Karma Automotive LLC</td>\n",
       "      <td>overview southern california based karma is mo...</td>\n",
       "      <td>reporting|analyze|reports|Design|modeling|mini...</td>\n",
       "      <td>0.180328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lead Data Scientist / Engineer</td>\n",
       "      <td>0.483980</td>\n",
       "      <td>AWM Smart Shelf (Adroit Worldwide Media, Inc.)</td>\n",
       "      <td>lead data scientist   engineer   aliso viejo  ...</td>\n",
       "      <td>retail|analytics|analysis|video|AI|AI|analysis...</td>\n",
       "      <td>0.114754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Staff Data Scientist</td>\n",
       "      <td>0.468772</td>\n",
       "      <td>Lifesprk</td>\n",
       "      <td>lifesprk s product and engineering team is gro...</td>\n",
       "      <td>engineering|System|healthcare|engineering|heal...</td>\n",
       "      <td>0.114754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.448187</td>\n",
       "      <td>ULTIMATE STAFFING SERVICES</td>\n",
       "      <td>key responsibilities data science focusing on ...</td>\n",
       "      <td>AI|Research|AI|healthcare|AI|AI|research|engin...</td>\n",
       "      <td>0.131148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.427393</td>\n",
       "      <td>Driveway</td>\n",
       "      <td>we are looking for a data scientist who will s...</td>\n",
       "      <td>sales|marketing|analytical|experiments|system|...</td>\n",
       "      <td>0.098361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst (Mortgage Banking)</td>\n",
       "      <td>0.419346</td>\n",
       "      <td>Matrix Resources</td>\n",
       "      <td>this nationwide mortgage industry leader has a...</td>\n",
       "      <td>mortgage|Mortgage|Banking|analysis|mortgage|ba...</td>\n",
       "      <td>0.032787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Financial Data Analyst w/PE backed Heal...</td>\n",
       "      <td>0.408271</td>\n",
       "      <td>Alliance Resource Group</td>\n",
       "      <td>senior financial data analyst w healthcare eco...</td>\n",
       "      <td>healthcare|economics|operations|healthcare|ana...</td>\n",
       "      <td>0.032787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SAP Data Analyst</td>\n",
       "      <td>0.406307</td>\n",
       "      <td>Fresh n' Lean</td>\n",
       "      <td>summary our organization is implementing sap b...</td>\n",
       "      <td>SAP|migration|SAP|SAP|writing|reports|ERP|SAP|...</td>\n",
       "      <td>0.065574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.366277</td>\n",
       "      <td>Spireon</td>\n",
       "      <td>this is us we have a bold vision to connect   ...</td>\n",
       "      <td>brand|design|reports|transportation|algorithms...</td>\n",
       "      <td>0.114754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Machine Learning Researcher</td>\n",
       "      <td>0.365700</td>\n",
       "      <td>BlackBerry</td>\n",
       "      <td>worker sub type regular job description the po...</td>\n",
       "      <td>security|security|statistics|modeling|engineer...</td>\n",
       "      <td>0.163934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.332069</td>\n",
       "      <td>Crossover Health</td>\n",
       "      <td>job description  designs  develops and program...</td>\n",
       "      <td>analyze|forecasts|modeling|analysis|experiment...</td>\n",
       "      <td>0.196721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Voice of the Customer Sr Data Analyst</td>\n",
       "      <td>0.277332</td>\n",
       "      <td>loanDepot</td>\n",
       "      <td>loandepot  america s lender  matches borrowers...</td>\n",
       "      <td>Marketing|Finance|Compliance|analysis|reportin...</td>\n",
       "      <td>0.032787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Machine Learning Architect</td>\n",
       "      <td>0.267420</td>\n",
       "      <td>Verys</td>\n",
       "      <td>important notes this position is fully remote ...</td>\n",
       "      <td>Orange|vendors|design|architecture|agile|Orang...</td>\n",
       "      <td>0.196721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Machine Learning Architect</td>\n",
       "      <td>0.267420</td>\n",
       "      <td>Verys</td>\n",
       "      <td>important notes this position is fully remote ...</td>\n",
       "      <td>Orange|vendors|design|architecture|agile|Orang...</td>\n",
       "      <td>0.196721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Scientist (Fraud &amp; Game Surveillance)</td>\n",
       "      <td>0.198495</td>\n",
       "      <td>NCSOFT</td>\n",
       "      <td>who we are ncsoft is a premiere digital entert...</td>\n",
       "      <td>mobile|design|engineering|improvement|SQL|Tabl...</td>\n",
       "      <td>0.065574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  job  word2vec  \\\n",
       "0                                      Data Scientist  0.493377   \n",
       "1                      Lead Data Scientist / Engineer  0.483980   \n",
       "2                         Senior Staff Data Scientist  0.468772   \n",
       "3                                      Data Scientist  0.448187   \n",
       "4                                      Data Scientist  0.427393   \n",
       "5              Senior Data Analyst (Mortgage Banking)  0.419346   \n",
       "6   Senior Financial Data Analyst w/PE backed Heal...  0.408271   \n",
       "7                                    SAP Data Analyst  0.406307   \n",
       "8                                      Data Scientist  0.366277   \n",
       "9                  Senior Machine Learning Researcher  0.365700   \n",
       "10                                     Data Scientist  0.332069   \n",
       "11              Voice of the Customer Sr Data Analyst  0.277332   \n",
       "12                         Machine Learning Architect  0.267420   \n",
       "13                         Machine Learning Architect  0.267420   \n",
       "14         Data Scientist (Fraud & Game Surveillance)  0.198495   \n",
       "\n",
       "                                           company  \\\n",
       "0                             Karma Automotive LLC   \n",
       "1   AWM Smart Shelf (Adroit Worldwide Media, Inc.)   \n",
       "2                                         Lifesprk   \n",
       "3                       ULTIMATE STAFFING SERVICES   \n",
       "4                                         Driveway   \n",
       "5                                 Matrix Resources   \n",
       "6                          Alliance Resource Group   \n",
       "7                                    Fresh n' Lean   \n",
       "8                                          Spireon   \n",
       "9                                       BlackBerry   \n",
       "10                                Crossover Health   \n",
       "11                                       loanDepot   \n",
       "12                                           Verys   \n",
       "13                                           Verys   \n",
       "14                                          NCSOFT   \n",
       "\n",
       "                                          description  \\\n",
       "0   overview southern california based karma is mo...   \n",
       "1   lead data scientist   engineer   aliso viejo  ...   \n",
       "2   lifesprk s product and engineering team is gro...   \n",
       "3   key responsibilities data science focusing on ...   \n",
       "4   we are looking for a data scientist who will s...   \n",
       "5   this nationwide mortgage industry leader has a...   \n",
       "6   senior financial data analyst w healthcare eco...   \n",
       "7   summary our organization is implementing sap b...   \n",
       "8   this is us we have a bold vision to connect   ...   \n",
       "9   worker sub type regular job description the po...   \n",
       "10  job description  designs  develops and program...   \n",
       "11  loandepot  america s lender  matches borrowers...   \n",
       "12  important notes this position is fully remote ...   \n",
       "13  important notes this position is fully remote ...   \n",
       "14  who we are ncsoft is a premiere digital entert...   \n",
       "\n",
       "                                               skills  skill_score  \n",
       "0   reporting|analyze|reports|Design|modeling|mini...     0.180328  \n",
       "1   retail|analytics|analysis|video|AI|AI|analysis...     0.114754  \n",
       "2   engineering|System|healthcare|engineering|heal...     0.114754  \n",
       "3   AI|Research|AI|healthcare|AI|AI|research|engin...     0.131148  \n",
       "4   sales|marketing|analytical|experiments|system|...     0.098361  \n",
       "5   mortgage|Mortgage|Banking|analysis|mortgage|ba...     0.032787  \n",
       "6   healthcare|economics|operations|healthcare|ana...     0.032787  \n",
       "7   SAP|migration|SAP|SAP|writing|reports|ERP|SAP|...     0.065574  \n",
       "8   brand|design|reports|transportation|algorithms...     0.114754  \n",
       "9   security|security|statistics|modeling|engineer...     0.163934  \n",
       "10  analyze|forecasts|modeling|analysis|experiment...     0.196721  \n",
       "11  Marketing|Finance|Compliance|analysis|reportin...     0.032787  \n",
       "12  Orange|vendors|design|architecture|agile|Orang...     0.196721  \n",
       "13  Orange|vendors|design|architecture|agile|Orang...     0.196721  \n",
       "14  mobile|design|engineering|improvement|SQL|Tabl...     0.065574  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>word2vec</th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>skills</th>\n",
       "      <th>skill_score</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.493797</td>\n",
       "      <td>Karma Automotive LLC</td>\n",
       "      <td>overview southern california based karma is mo...</td>\n",
       "      <td>reporting|analyze|reports|Design|modeling|mini...</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>1.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.330854</td>\n",
       "      <td>Crossover Health</td>\n",
       "      <td>job description  designs  develops and program...</td>\n",
       "      <td>analyze|forecasts|modeling|analysis|experiment...</td>\n",
       "      <td>0.196721</td>\n",
       "      <td>1.670020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Machine Learning Researcher</td>\n",
       "      <td>0.357839</td>\n",
       "      <td>BlackBerry</td>\n",
       "      <td>worker sub type regular job description the po...</td>\n",
       "      <td>security|security|statistics|modeling|engineer...</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>1.558002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lead Data Scientist / Engineer</td>\n",
       "      <td>0.479266</td>\n",
       "      <td>AWM Smart Shelf (Adroit Worldwide Media, Inc.)</td>\n",
       "      <td>lead data scientist   engineer   aliso viejo  ...</td>\n",
       "      <td>retail|analytics|analysis|video|AI|AI|analysis...</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>1.553906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.433522</td>\n",
       "      <td>ULTIMATE STAFFING SERVICES</td>\n",
       "      <td>key responsibilities data science focusing on ...</td>\n",
       "      <td>AI|Research|AI|healthcare|AI|AI|research|engin...</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>1.544602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Machine Learning Architect</td>\n",
       "      <td>0.265119</td>\n",
       "      <td>Verys</td>\n",
       "      <td>important notes this position is fully remote ...</td>\n",
       "      <td>Orange|vendors|design|architecture|agile|Orang...</td>\n",
       "      <td>0.196721</td>\n",
       "      <td>1.536898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Machine Learning Architect</td>\n",
       "      <td>0.265119</td>\n",
       "      <td>Verys</td>\n",
       "      <td>important notes this position is fully remote ...</td>\n",
       "      <td>Orange|vendors|design|architecture|agile|Orang...</td>\n",
       "      <td>0.196721</td>\n",
       "      <td>1.536898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Staff Data Scientist</td>\n",
       "      <td>0.467325</td>\n",
       "      <td>Lifesprk</td>\n",
       "      <td>lifesprk s product and engineering team is gro...</td>\n",
       "      <td>engineering|System|healthcare|engineering|heal...</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>1.529725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.427810</td>\n",
       "      <td>Driveway</td>\n",
       "      <td>we are looking for a data scientist who will s...</td>\n",
       "      <td>sales|marketing|analytical|experiments|system|...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>1.366368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.348155</td>\n",
       "      <td>Spireon</td>\n",
       "      <td>this is us we have a bold vision to connect   ...</td>\n",
       "      <td>brand|design|reports|transportation|algorithms...</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>1.288389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SAP Data Analyst</td>\n",
       "      <td>0.395457</td>\n",
       "      <td>Fresh n' Lean</td>\n",
       "      <td>summary our organization is implementing sap b...</td>\n",
       "      <td>SAP|migration|SAP|SAP|writing|reports|ERP|SAP|...</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>1.134184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst (Mortgage Banking)</td>\n",
       "      <td>0.419705</td>\n",
       "      <td>Matrix Resources</td>\n",
       "      <td>this nationwide mortgage industry leader has a...</td>\n",
       "      <td>mortgage|Mortgage|Banking|analysis|mortgage|ba...</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>1.016621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Financial Data Analyst w/PE backed Heal...</td>\n",
       "      <td>0.403786</td>\n",
       "      <td>Alliance Resource Group</td>\n",
       "      <td>senior financial data analyst w healthcare eco...</td>\n",
       "      <td>healthcare|economics|operations|healthcare|ana...</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.984382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Voice of the Customer Sr Data Analyst</td>\n",
       "      <td>0.253421</td>\n",
       "      <td>loanDepot</td>\n",
       "      <td>loandepot  america s lender  matches borrowers...</td>\n",
       "      <td>Marketing|Finance|Compliance|analysis|reportin...</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.679875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Scientist (Fraud &amp; Game Surveillance)</td>\n",
       "      <td>0.159092</td>\n",
       "      <td>NCSOFT</td>\n",
       "      <td>who we are ncsoft is a premiere digital entert...</td>\n",
       "      <td>mobile|design|engineering|improvement|SQL|Tabl...</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.655514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  job  word2vec  \\\n",
       "0                                      Data Scientist  0.493797   \n",
       "10                                     Data Scientist  0.330854   \n",
       "8                  Senior Machine Learning Researcher  0.357839   \n",
       "1                      Lead Data Scientist / Engineer  0.479266   \n",
       "3                                      Data Scientist  0.433522   \n",
       "11                         Machine Learning Architect  0.265119   \n",
       "12                         Machine Learning Architect  0.265119   \n",
       "2                         Senior Staff Data Scientist  0.467325   \n",
       "4                                      Data Scientist  0.427810   \n",
       "9                                      Data Scientist  0.348155   \n",
       "7                                    SAP Data Analyst  0.395457   \n",
       "5              Senior Data Analyst (Mortgage Banking)  0.419705   \n",
       "6   Senior Financial Data Analyst w/PE backed Heal...  0.403786   \n",
       "13              Voice of the Customer Sr Data Analyst  0.253421   \n",
       "14         Data Scientist (Fraud & Game Surveillance)  0.159092   \n",
       "\n",
       "                                           company  \\\n",
       "0                             Karma Automotive LLC   \n",
       "10                                Crossover Health   \n",
       "8                                       BlackBerry   \n",
       "1   AWM Smart Shelf (Adroit Worldwide Media, Inc.)   \n",
       "3                       ULTIMATE STAFFING SERVICES   \n",
       "11                                           Verys   \n",
       "12                                           Verys   \n",
       "2                                         Lifesprk   \n",
       "4                                         Driveway   \n",
       "9                                          Spireon   \n",
       "7                                    Fresh n' Lean   \n",
       "5                                 Matrix Resources   \n",
       "6                          Alliance Resource Group   \n",
       "13                                       loanDepot   \n",
       "14                                          NCSOFT   \n",
       "\n",
       "                                          description  \\\n",
       "0   overview southern california based karma is mo...   \n",
       "10  job description  designs  develops and program...   \n",
       "8   worker sub type regular job description the po...   \n",
       "1   lead data scientist   engineer   aliso viejo  ...   \n",
       "3   key responsibilities data science focusing on ...   \n",
       "11  important notes this position is fully remote ...   \n",
       "12  important notes this position is fully remote ...   \n",
       "2   lifesprk s product and engineering team is gro...   \n",
       "4   we are looking for a data scientist who will s...   \n",
       "9   this is us we have a bold vision to connect   ...   \n",
       "7   summary our organization is implementing sap b...   \n",
       "5   this nationwide mortgage industry leader has a...   \n",
       "6   senior financial data analyst w healthcare eco...   \n",
       "13  loandepot  america s lender  matches borrowers...   \n",
       "14  who we are ncsoft is a premiere digital entert...   \n",
       "\n",
       "                                               skills  skill_score     score  \n",
       "0   reporting|analyze|reports|Design|modeling|mini...     0.180328  1.916667  \n",
       "10  analyze|forecasts|modeling|analysis|experiment...     0.196721  1.670020  \n",
       "8   security|security|statistics|modeling|engineer...     0.163934  1.558002  \n",
       "1   retail|analytics|analysis|video|AI|AI|analysis...     0.114754  1.553906  \n",
       "3   AI|Research|AI|healthcare|AI|AI|research|engin...     0.131148  1.544602  \n",
       "11  Orange|vendors|design|architecture|agile|Orang...     0.196721  1.536898  \n",
       "12  Orange|vendors|design|architecture|agile|Orang...     0.196721  1.536898  \n",
       "2   engineering|System|healthcare|engineering|heal...     0.114754  1.529725  \n",
       "4   sales|marketing|analytical|experiments|system|...     0.098361  1.366368  \n",
       "9   brand|design|reports|transportation|algorithms...     0.114754  1.288389  \n",
       "7   SAP|migration|SAP|SAP|writing|reports|ERP|SAP|...     0.065574  1.134184  \n",
       "5   mortgage|Mortgage|Banking|analysis|mortgage|ba...     0.032787  1.016621  \n",
       "6   healthcare|economics|operations|healthcare|ana...     0.032787  0.984382  \n",
       "13  Marketing|Finance|Compliance|analysis|reportin...     0.032787  0.679875  \n",
       "14  mobile|design|engineering|improvement|SQL|Tabl...     0.065574  0.655514  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wvec['score'] = df_wvec.word2vec / df_wvec.word2vec.max()+ df_wvec.skill_score / df_wvec.skill_score.max()\n",
    "df_wvec.sort_values(by='score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AI',\n",
       " 'Research',\n",
       " 'AI',\n",
       " 'healthcare',\n",
       " 'AI',\n",
       " 'AI',\n",
       " 'research',\n",
       " 'engineering',\n",
       " 'healthcare',\n",
       " 'healthcare',\n",
       " 'datasets',\n",
       " 'research',\n",
       " 'healthcare',\n",
       " 'AI',\n",
       " 'research',\n",
       " 'research',\n",
       " 'Python',\n",
       " 'SQL',\n",
       " 'Tableau',\n",
       " 'modeling',\n",
       " 'Python',\n",
       " 'SQL',\n",
       " 'NoSQL',\n",
       " 'Tensorflow',\n",
       " 'PyTorch',\n",
       " 'Tableau',\n",
       " 'communication',\n",
       " 'AWS',\n",
       " 'Statistics',\n",
       " 'Statistics',\n",
       " 'analytical',\n",
       " 'Recruitment',\n",
       " 'training',\n",
       " 'email',\n",
       " 'machine learning',\n",
       " 'ai',\n",
       " 'healthcare',\n",
       " 'engineering',\n",
       " 'machine learning',\n",
       " 'healthcare',\n",
       " 'python',\n",
       " 'sql',\n",
       " 'tableau',\n",
       " 'modeling',\n",
       " 'python',\n",
       " 'sql',\n",
       " 'nosql',\n",
       " 'tensorflow',\n",
       " 'pytorch',\n",
       " 'aws',\n",
       " 'statistics',\n",
       " 'statistics',\n",
       " 'recruitment',\n",
       " 'training']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = df_wvec.loc[3,'skills'].split('|')\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AWS',\n",
       " 'Python',\n",
       " 'analytical',\n",
       " 'aws',\n",
       " 'email',\n",
       " 'machine learning',\n",
       " 'python',\n",
       " 'research'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(s) & set(res_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data Scientist\n",
      "ROBERT SMITH\n",
      "\n",
      "Phone: (123) 456 78 99 \n",
      "Email: info@qwikresume.com\n",
      "Website: www.qwikresume.com\n",
      "LinkedIn:\n",
      "linkedin.com/qwikresume\n",
      "Address: 1737 Marshville Road,\n",
      "Alabama.\n",
      "\n",
      "Objective\n",
      "Data Scientist with PhD in Physics and 1+ industrial experience. Two years of working experience \n",
      "in Data Analysis team of LIGO Scientific Collaboration [$3M Special Breakthrough Prize winner of \n",
      "2016]. Over ten years of successful research experience in both theoretical and computational \n",
      "physics. Strong problem-solving and analytical skills. Advanced programming proficiency. Certified\n",
      "in Data Analysis and Machine Learning.\n",
      "Skills\n",
      "\n",
      "Data Mining, Data Analysis, Machine Learning, Python, R, MATLAB, Sphinx, LaTeX, Mathematica, \n",
      "Maple, GIT, CVS, HTCondor.\n",
      "Work Experience\n",
      "Data Scientist\n",
      "ABC Corporation ­ May 1994 – May 2005 \n",
      " Assisted in determining client needs, deliverable design, estimates and feasibility for \n",
      "\n",
      "analytical projects concerning a custom study for a manufacturer who is using the results to \n",
      "support a litigation claim.\n",
      "\n",
      " Served as an internal resource for Jacknife programming and documentation.\n",
      " Designed and developed small scale deliverables related to the custom study.\n",
      " Participated in the Post Project Review QIP team.\n",
      " Responsible for results reporting in the appropriate media and creation of supporting \n",
      " Monitored products from statistical programs for accuracy, consistency and statistical validity.\n",
      " Designed and applied statistical and mathematical methods for corporate analytics that were \n",
      "\n",
      "documentation for the client.\n",
      "\n",
      "implemented into client-facing products.\n",
      "\n",
      "Data Scientist\n",
      "ABC Corporation ­ 1993 – 1994 \n",
      " Maintained automated ETL for reporting.\n",
      "\n",
      "\n",
      "Implemented Data mining and machine learning algorithms to describe and predict user \n",
      "behavior on various retailer websites.\n",
      "I revamped their &quot;Predictive Marketing&quot; process to be more data driven and \n",
      "profitable.\n",
      "increase in conversion.\n",
      "\n",
      "\n",
      " The new process was able to hone in on more useful user segments that had a significant \n",
      " Skills Used Data Cleansing and Data Analysis using Python, Scala, R and Spark.\n",
      " Cloud computing on AWS.\n",
      " Automation of reporting..\n",
      "\n",
      "Education\n",
      "\n",
      "© This Free Resume Template is the copyright of Qwikresume.com. Usage\n",
      "\n",
      "Guidelines\n",
      "\n",
      "\f",
      " Bachelor Of Science - (Stanford)\n",
      "\n",
      "© This Free Resume Template is the copyright of Qwikresume.com. Usage\n",
      "\n",
      "Guidelines\n",
      "\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.indeed.com/rc/clk?jk=f7fd2a35541c62d2&fccid=87d7af0ec9cd5df0&vjs=3'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(job_dict).loc[5,'url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'overview southern california based karma is more than just a car company although we are best known as a creator of soul stirring luxury electric vehicles  karma has emerged as a high tech incubator offering innovators a perfect platform to prove their emerging technologies every revero is designed at our headquarters in irvine and created with great individual care and world class craftsmanship at the karma innovation and customization center in moreno valley  ca the data scientist reporting to the manager  data sciences and innovation  is responsible for data collection analyze  extract  normalize  and label relevant data from multiple sources to provide interpretation and visualizations reports around key data driven projects responsibilities design and build new data set processes for modeling  data mining  and production purposes determine new ways to improve data and search quality  and predictive capabilities perform and interpret data studies and product experiments concerning new data sources or new uses for existing data sources develop prototypes  proof of concepts  algorithms  predictive models  and custom analysis create visualizations and reports to show insights obtained from data mining efforts interact with multiple internal and external sources in support of ongoing and proof of concept projects ensure timely  accurate and credible information is provided and interpreted and distilled into action driven information for diverse audiences attend trade shows  conferences and learning opportunity to familiarize with the industry leading trends in data sciences and predictive analytics to help drive karma s data sciences and technology department development other duties  as assigned'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wvec.loc[0,'description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lead data scientist   engineer   aliso viejo  ca awm smart shelf is reinventing retail and looking for smart  talented people to help build on our current and future data and analytics platforms  pipelines  and machine learning models our solutions encompass a wide range of data such as real time computer vision and deep learning that enables an understanding of what shoppers and workers are doing  e g movement  actions  product selection  etc awm frictionless  shopping  cashierless checkout demographic data captured via anonymous facial analysis ads video playback and effectiveness product placement and pricing the ideal candidate will have the ability to use modern techniques to understand and interpret data  reaching meaningful conclusions based on solid premises predict optimizations both in real time and via big data processing handle large and rapidly growing data sets job duties contributing to the development and maintenance of data pipelines as well as creation of new ones based on ai computer vision and other data sources validation of ai models and big data analysis performing ad hoc analysis on proprietary datasets for internal and external stakeholders annotating proprietary datasets and giving direction to data labelers performing exploratory analysis on data to find trends training and evaluating various machine learning models'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wvec.loc[1,'description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Original (Simple Cosine Similarity)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(file):\n",
    "    # Store the resume in a variable\n",
    "    #filename = askopenfilename()\n",
    "    filename = file\n",
    "    resume = extract_text(filename)\n",
    "\n",
    "    # Print the resume\n",
    "    #print(resume)\n",
    "    stat = dict()\n",
    "\n",
    "    for filename in os.listdir(\"./test_job\"):\n",
    "        # Store the job description into a variable\n",
    "        with open(\"./test_job/\"+filename,'r+',encoding='utf-8') as file:\n",
    "            job_description = file.read()\n",
    "#         job_description = docx2txt.process(\"./test_job/\"+filename)\n",
    "\n",
    "        # Print the job description\n",
    "        print(job_description)\n",
    "\n",
    "        # A list of text\n",
    "        text = [resume, job_description]\n",
    "\n",
    "        cv = CountVectorizer()\n",
    "        count_matrix = cv.fit_transform(text)\n",
    "\n",
    "        #Print the similarity scores\n",
    "        #print(\"\\nSimilarity Scores:\")\n",
    "        #print(cosine_similarity(count_matrix))\n",
    "\n",
    "        #get the match percentage\n",
    "        matchPercentage = cosine_similarity(count_matrix)[0][1] * 100\n",
    "        matchPercentage = round(matchPercentage, 2) # round to two decimal\n",
    "        stat[(resume,filename)] = matchPercentage\n",
    "        print(\"Your resume matches about \"+ str(matchPercentage)+ \"% of the job description:\"+ filename)\n",
    "\n",
    "    match = Counter(stat)\n",
    "    top5 = match.most_common(5)\n",
    "    output = 'Your top job recommendations are:'\n",
    "    for (temp_resume,temp_match) in top5:\n",
    "        print(temp_resume[1],temp_match,\"% matching\")\n",
    "        output += \"\\n\"+str(temp_resume[1][:-4])+\" \"+str(temp_match)+\" % macthing\"+\"|\"\n",
    "    print(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿Business Analyst\n",
      "We’re looking for a Business Analyst to evaluate business processes, identify startup needs, and develop strategies to maximize opportunities for the various Forkaia incubator companies. The Business Analyst may work with business, IT and test systems. Some create documentation and manuals. Business Analysts interact with developers, stakeholders, system architects and various subject experts.\n",
      "Responsibilities\n",
      "Collecting and analyzing data for potential business expansion\n",
      "Identifying specific business opportunities\n",
      "Influencing stakeholders to support business projects\n",
      "Leading projects and coordinating with other teams to produce better business outcomes\n",
      "Testing business processes and recommending improvements\n",
      "Skills and Qualifications\n",
      "Excellent written and verbal communication skills\n",
      "Great analytical, critical thinking and problem-solving abilities\n",
      "Superior presentation and negotiation skills\n",
      "Proven management and organizational skills\n",
      "Strong adaptability and capacity to work in fast-paced environments\n",
      "In-depth understanding of organizational data flow and its use in management decision-making\n",
      "Two or more years of Business Analyst experience\n",
      "Bachelor's degree or higher in business analysis, business administration, finance or related field\n",
      "\n",
      "\n",
      "Your resume matches about 48.74% of the job description:Business Analyst.txt\n",
      "﻿Business Consultant\n",
      "Our company is looking for a Business Consultant who can help us to improve business processes to better serve our clients. The successful candidate for this position will partner with executive management to review our current business operations processes and make recommendations to improve efficiency, enhance customer service and reduce company costs. Individuals with a strong background in consulting within the manufacturing sector are encouraged to apply for this position.\n",
      "Responsibilities:\n",
      "Partner with executive management team to assess and improve current business processes\n",
      "Establish methods for testing business applications and create templates for reports used to monitor application effectiveness\n",
      "Monitor the communication between various departments to make sure that the customer service team is getting the information it needs to improve customer satisfaction\n",
      "Work closely with key customers to keep them updated on process changes designed to improve service\n",
      "Submit regular reports to management team about company health and new initiatives in progress\n",
      "Skills and Qualifications\n",
      "MBA Preferred\n",
      "5+ years’ business consulting experience\n",
      "10+ years’ experience in the manufacturing sector\n",
      "Must be willing to travel at least two weeks out of every month\n",
      "Strong problem solving skills\n",
      "Excellent written and verbal communication skills\n",
      "\n",
      "\n",
      "Your resume matches about 43.87% of the job description:Business Consultant.txt\n",
      "﻿Business Development Specialist\n",
      "We are looking for a business development specialist who values communication and can foment cooperation between various parties. \n",
      "Essential Duties and Responsibilities of a Business Development Specialist:\n",
      "Develops and executes a strategy for discovering and securing new business opportunities either locally, regionally, or nationally.\n",
      "Assesses potential third party clients in terms of income potential and mission fit.\n",
      "Adapts new business strategies in accordance with the types of clients already secured by the company.\n",
      "Evaluates, determines, and realizes quarterly business growth goals.\n",
      "Represents the company at trade organizations, on committees, and during board meetings, when necessary.\n",
      "Creates a business development database in order to evaluate performance and organize client and prospective client information.\n",
      "Fosters beneficial relationships with business partners, potential clients, and business contacts in order to attract new business and enhance organization reputation.\n",
      "\n",
      "Required Knowledge, Skills, and Abilities:\n",
      "Is able to close deals and achieve goals.\n",
      "Exhibits strong motivation to make sales.\n",
      "Is detail-oriented and able to multitask.\n",
      "Demonstrates strong organizational skills, the ability to meet deadlines, and the ability to solve problems.\n",
      "Exhibits excellent communication skills.\n",
      "Is an extremely flexible and adaptable self-starter.\n",
      "\n",
      "\n",
      "Your resume matches about 51.21% of the job description:Business Development Specialist.txt\n",
      "﻿Computer Programmer\n",
      "We are looking for a meticulous and technically skilled Computer Programmer to develop and maintain our organization's systems software and computing infrastructure. The Computer Programmer's duties will include managing systems performance, providing tech support, reviewing and updating existing programs, identifying and fixing defects, supporting data architecture, generating reports, developing in-house software, and mitigating potential risk. Your expertise in the craft of programming will assist our organization in increasing efficiency and service through construction, maintenance, and streamlining of our computing systems and programs.\n",
      "\n",
      "The ideal candidate for this role must possess superior coding skills, excellent communication, high concentration levels, good task management, and superior problem solving and critical thinking skills. Essentially, the outstanding Computer Programmer must enhance the efficiency and cost-effectiveness of systems, resolve errors, and design programs that are customized to our organization's needs.\n",
      "Computer Programmer Responsibilities:\n",
      "Coding and debugging.\n",
      "Designing and testing computer structures.\n",
      "Troubleshooting system errors.\n",
      "Writing computer instructions.\n",
      "Managing database systems.\n",
      "Maintaining operating systems.\n",
      "Editing source-code.\n",
      "Profiling and analyzing algorithms.\n",
      "Implementing build systems.\n",
      "Providing tech support.\n",
      "Computer Programmer Requirements:\n",
      "Degree in Computer Science or Computer Programming.\n",
      "End user oriented.\n",
      "Expert IT skills.\n",
      "Strong aptitude for math.\n",
      "Advanced knowledge of operating systems.\n",
      "Analytical and problem solving skills.\n",
      "Java, C++, SQL, C#, and HTML experience.\n",
      "Aptitude for learning new technology.\n",
      "Deadline driven.\n",
      "Superior communication skills.\n",
      "\n",
      "\n",
      "Your resume matches about 51.43% of the job description:Computer Programmer.txt\n",
      "﻿Content Writer/Editor\n",
      "INSOLAR seeks a talented, meticulous writer, editor, and researcher to join our office. An integral member of the team, the Writer/Editor will create content that advances the company’s story across multiple platforms. The Writer/Editor will research, produce, proofread, and copy-edit a variety of digital and print materials. \n",
      "Responsibilities\n",
      "Research and write a range of content, including publicity items about solar industry, solar facts, industry news; press, marketing, and development materials; web content; social media posts; Q&As; e-newsletters, and more\n",
      "Serve as the in-house proofreader, fact checker, and copy editor\n",
      "Report on and write articles about company events\n",
      "Participate in editorial planning meetings, generate story ideas, and keep track of upcoming solar industry events and news that might make for good editorial and news content. \n",
      "Assist with special projects and other assignments as needed. \n",
      "Qualifications: \n",
      "Excellent written, verbal, and interpersonal communication skills\n",
      "Demonstrated ability to write for a range of audiences and content types, including marketing, news, social media, etc.\n",
      "Top-notch copy-editing and proofreading skills\n",
      "Educational background in business or journalism preferred.\n",
      "\n",
      "\n",
      "Your resume matches about 50.26% of the job description:Content WriterEditor.txt\n",
      "﻿Customer Service Assistant\n",
      "We are currently seeking a motivated, enthusiastic, and reliable Customer Service Assistant to join our ever-growing team of professionals. In this role, you will interact with our clients one-on-one on a daily basis, addressing concerns, making sales, and fielding questions. To be successful in this position, you will be self-motivated, persistent, and knowledgeable, with a friendly yet professional demeanor.\n",
      "Major Duties and Responsibilities:\n",
      "Interact with clients on the phone, internet, and face-to-face in a professional manner\n",
      "Meet all customer needs and exceed expectations, upholding our strong reputation to make sure that the customer's experience is a positive one.\n",
      "Accurately answer questions and address client concerns\n",
      "Log all contacts in our customer database system accurately\n",
      "Maintain accurate and up to date client files\n",
      "Suggest additional products and services of use to clients\n",
      "Investigate and pursue client leads, expanding our client base\n",
      "Conduct basic administrative tasks such and copying and filing\n",
      "Generate monthly, quarterly, and annual reports for management\n",
      "Proactively seek solutions to problems, notifying Management when concerns arise\n",
      "\n",
      "Qualifications and skills:\n",
      "Exceptional communication skills, both written and verbal\n",
      "A polite, friendly and tactful manner, when handling complaints or enquiries or solving problems.\n",
      "The ability to work well under pressure.\n",
      "Outstanding phone and email etiquette\n",
      "Keen attention to detail and excellent memory, making clients feel known\n",
      "\n",
      "\n",
      "Your resume matches about 51.44% of the job description:Customer Service Assistant.txt\n",
      "﻿Data Analyst\n",
      "We’re looking for a Data Analyst who is able to turn project requirements into custom-formatted data reports. The ideal candidate for this position is able to do complete life cycle data generation and outline critical information for each Project Manager. We also need someone who is able to analyze business procedures and recommend specific types of data that can be used to improve upon them.\n",
      "\n",
      "Responsibilities\n",
      "Use statistical methods to analyze data and generate useful business reports\n",
      "Work with management team to create a prioritized list of needs for each business segment\n",
      "Identify and recommend new ways to save money by streamlining business processes\n",
      "Use data to create models that depict trends in the customer base and the consumer population as a whole\n",
      "Work with departmental managers to outline the specific data needs for each business method analysis project\n",
      "Skills and Qualifications\n",
      "Bachelor’s Degree in Mathematics or Computer Engineering\n",
      "2+ years’ Data mining experience\n",
      "4+ years in a data analyst role\n",
      "Ability to collaborate effectively and work as part of a team\n",
      "Strong attention to detail\n",
      "\n",
      "\n",
      "Your resume matches about 60.35% of the job description:Data Analyst.txt\n",
      "﻿Data Scientist\n",
      "We are looking for a data scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products. Projects include: automate scoring using machine learning techniques, build recommendation systems, improve and extend the features used by our existing classifier, develop internal A/B testing procedures, build systems for automated fraud detection, etc.\n",
      "\n",
      "Responsibilities\n",
      "Selecting features, building and optimizing classifiers using machine learning techniques\n",
      "Data mining using state-of-the-art methods\n",
      "Extending company’s data with third party sources of information when needed\n",
      "Enhancing data collection procedures to include information that is relevant for building analytic systems\n",
      "Processing, cleansing, and verifying the integrity of data used for analysis\n",
      "Doing ad-hoc analysis and presenting results in a clear manner\n",
      "Creating automated anomaly detection systems and constant tracking of its performance\n",
      "Skills and Qualifications\n",
      "Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.\n",
      "Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc . Excellence in at least one of these is highly desirable\n",
      "Great communication skills\n",
      "Experience with data visualisation tools, such as D3.js, GGplot, etc.\n",
      "Proficiency in using query languages such as SQL, Hive, Pig \n",
      "Experience with NoSQL databases, such as MongoDB, Cassandra, HBase \n",
      "Good applied statistics skills, such as distributions, statistical testing, regression, etc.\n",
      "Good scripting and programming skills \n",
      "Data-oriented personality\n",
      "\n",
      "\n",
      "Your resume matches about 62.99% of the job description:Data Scientist.txt\n",
      "﻿Fashion Designer\n",
      "Our startup athleisure apparel company BAM is looking for a creative and ambitious Fashion Designer. Someone who understands the principles of design and is able to apply this knowledge to creating aesthetically pleasing and functional pieces. The designer will create designs for fashion items such as clothes, shoes and bags as well as clothing accessories such as belts, scarves, stockings and more.\n",
      "Responsibilities include, but are not limited to:\n",
      "Researching current fashion trends and determining what consumers will like\n",
      "Collaborating with the design team to develop ideas for new products based on research data\n",
      "Designing sketches for new products with a design team\n",
      "Creating clothing patterns for mass production\n",
      "Testing and deciding on fabrics, colors, patterns and textures for each design\n",
      "Overseeing the production of designs, including carrying out fittings, determining prices and managing marketing\n",
      "Maintaining relationships with vendors, suppliers and models\n",
      "\n",
      "Important Skills/Traits:\n",
      "Superior knowledge of fashion design principles\n",
      "Excellent creativity with a good sense of fashion and style\n",
      "In-depth knowledge of garment technology\n",
      "Ability to create, cut and sew-up patterns\n",
      "Proficiency in computer-aided fashion design applications and digital visualization tools\n",
      "Strong interpersonal and communication skills\n",
      "Strong time-management skills\n",
      "Excellent attention to detail\n",
      "\n",
      "\n",
      "Your resume matches about 54.9% of the job description:Fashion Designer.txt\n",
      "﻿Financial Analyst\n",
      "High Tech Startup Incubator seeks a Financial Analyst to manage and coordinate all aspects of accounting. The successful candidate will be responsible for analyzing revenue, credit, expenses and overhead. He or she will supervise the A/R and A/P department and work closely with senior management and CEO to help make critical decisions about investment funding, credit extension and expense management. If you are highly detail-oriented and capable of analyzing data with creativity and innovation in mind, you might be perfect for this position.\n",
      "Responsibilities:\n",
      "Gather and organize financial data from all accounting departments\n",
      "Compile and analyze financial reports and find discrepancies that require senior management’s attention\n",
      "Manage the general ledger and devote time to risk management, especially with regard to accounts receivable\n",
      "Prepare financial reports with reliable conclusions that management can use to implement more effective operational strategies\n",
      "Forecast models for revenue changes and expenditure increases/decreases\n",
      "Provide EOM reports for C-level executives\n",
      "Skills and Qualifications\n",
      "Knowledge of Quicken and JD Edwards EnterpriseOne\n",
      "Bachelor’s Degree in Finance (MBA preferred)\n",
      "Demonstrated ability to assess credit risks accurately\n",
      "Experience creating financial statements and financial reports \n",
      "\n",
      "\n",
      "Your resume matches about 52.69% of the job description:Financial Analyst.txt\n",
      "﻿Graphic Designer\n",
      "We are looking for a creative, innovative designer with a passion for the solar industry to join our team.  You’ll be responsible to determine the layout, font color, font type, logos, pictures and other visual and verbal aspects of our company website and app. \n",
      "The successful candidate will be able to create amazing user experiences and have an eye for clean and artful web design. Superior user interface design skills are also desired. You will be able to translate high-level requirements into interaction flows and artifacts, into beautiful, intuitive, and functional designs.\n",
      "Qualifications:\n",
      "Advanced graphics design skills\n",
      "Advanced digital media & video production skills\n",
      "Advanced written communications skills\n",
      "Exceptional project management, organization and coordination skills.\n",
      "Advanced knowledge of PowerPoint\n",
      "Advanced knowledge in Adobe Photoshop, Illustrator\n",
      "Supporting knowledge of After Effects, Final cut pro, InDesign\n",
      "\n",
      "\n",
      "Your resume matches about 47.1% of the job description:Graphic Designer.txt\n",
      "﻿Industrial Engineer\n",
      "Our solar startup INSOLAR is looking for a creative and ambitious Industrial Designer. The qualified individual will design efficient systems that integrate workers, information, machines, energy and materials to make products or provide services as well as equipment to coordinate production planning to minimize production issues and costs while ensuring products meet quality standards. \n",
      "Responsibilities include, but are not limited to:\n",
      "Review production information to understand methods and activities in manufacturing and services. This includes, but is not limited to, production schedules, process flows and engineering specs.\n",
      "Design control systems to minimize and resolve production issues and project costs.\n",
      "Create systems and plan production to ensure all products meet quality control standards.\n",
      "Develop standards for production and design by working with clients and management. \n",
      "Important Skills/Traits:\n",
      "Knowledge of production processes, costs, quality control, raw materials and other methods for maximizing the efficient manufacture and distribution of goods.\n",
      "Advanced knowledge of machines and tools, their designs, uses, repair and maintenance.\n",
      "Ability to design and understand precision technical plans, blueprints, drawings and models.\n",
      "Knowledge of the ways various systems interact and how changes in operations, the environment and other conditions will affect outcomes.\n",
      "\n",
      "\n",
      "Your resume matches about 51.97% of the job description:Industrial Engineer.txt\n",
      "﻿Project Manager\n",
      "We are looking for a Project Manager to be responsible for handling our company's ongoing projects. You will be working closely with your team members to ensure that all project requirements, deadlines, and schedules are on track. Responsibilities include submitting project deliverables, preparing status reports, and establishing effective project communication plans as well as the proper execution of said plans.\n",
      "To be a successful candidate, you will need to have proven experience in project management and the ability to lead project teams of various sizes. A Project Management Professional (PMP) certification is a huge advantage.\n",
      "Project Manager Responsibilities:\n",
      "Coordinating with cross discipline team members to make sure that all parties are on track with project requirements, deadlines, and schedules.\n",
      "Meeting with project team members to identify and resolve issues.\n",
      "Submitting project deliverables and ensuring that they adhere to quality standards.\n",
      "Preparing status reports by gathering, analyzing and summarizing relevant information.\n",
      "Establishing effective project communication plans and ensuring their execution.\n",
      "Facilitating change requests to ensure that all parties are informed of the impacts on schedule and budget.\n",
      "Coordinating the development of user manuals, training materials and other documents as needed to enable successful implementation and turnover of the process or system to the clients.\n",
      "Identifying and developing new opportunities with clients.\n",
      "Obtaining customer acceptance of project deliverables.\n",
      "Managing customer satisfaction within the project transition period.\n",
      "Conducting post project evaluation and identifying successful and unsuccessful project elements.\n",
      "ERP project oversight.\n",
      "Project Manager Requirements:\n",
      "A bachelor’s degree or master degree in a related field.\n",
      "Project Management Professional (PMP) certification is a plus.\n",
      "Proven experience in project management.\n",
      "Ability to lead project teams of various sizes and see them through to completion.\n",
      "Strong understanding of formal project management methodologies.\n",
      "Experience as a construction project manager, IT project manager or ERP project manager.\n",
      "Able to complete projects in a timely manner.\n",
      "Understanding of ERP implementation.\n",
      "Experience overseeing a construction project.\n",
      "Budget management experience.\n",
      "\n",
      "\n",
      "Your resume matches about 42.05% of the job description:Project Manager.txt\n",
      "﻿Public Relations Coordinator\n",
      "We are looking for a PR Coordinator who’ll help the team manage the public image of the company, with the aim of increasing our media presence and overall popularity. \n",
      "Responsibilities include, but are not limited to:\n",
      "Working with Marketing team to integrate PR campaigns with customer promotions\n",
      "Handling all aspects of different PR activities and strategies in order to manage the company’s or their clients’ public image\n",
      "Drafting and distributing press releases, fact sheets, and media invites, along with any other communication \n",
      "Keeping abreast of industry and competitive trends and regularly informing sales and marketing of noteworthy news items and opportunities\n",
      "Coordinating industry events, including user group meetings and trade shows; Making appointments with all at major trade shows\n",
      "Coordinating industry events, including user group meetings and trade shows\n",
      "Working with Marketing Manager to develop and refine measurement strategies for PR campaigns\n",
      "Important Skills/Traits\n",
      "Excellent analytical and presentation skills including handling many assignments simultaneously\n",
      "Effectively balance strategic thinking and execution in a fast-paced environment\n",
      "Should exhibit creativity and resourcefulness\n",
      "Self-confident and outgoing personality\n",
      "Organized and detail oriented\n",
      "Excellent communication skills (verbal and written)\n",
      "Entrepreneurial attitude and ability to think outside the box\n",
      "\n",
      "\n",
      "Your resume matches about 52.73% of the job description:Public Relations Coordinator.txt\n",
      "﻿Social Media Marketing Specialist\n",
      "INSOLAR is a technology company that connects solar customers with the best solar panel installers at the lowest prices in the market using Artificial Intelligence. We are looking for a social media marketing specialist who will administer the company’s social media marketing and advertising. \n",
      "Essential duties and responsibilities includes but not limited to:\n",
      "Create social content optimized for major social platforms including Facebook, LinkedIn, YouTube, Twitter and Instagram\n",
      "Develop and administer online marketing campaigns, brand awareness and reputation\n",
      "Facilitate online conversations with customers and respond to social media posts, comments and inquiries in a timely, formative, appropriate way\n",
      "Develop optimal posting scheduling, considering customer engagement metrics and best practices\n",
      "Collect customer data and analyse interactions and visits, effectively use this information to create comprehensive reports to improve future marketing campaigns. \n",
      "Partner with the business development team to develop and execute social media strategies to drive sales and increase engagement with existing and potential customers. \n",
      "Qualifications: \n",
      "Excellent organizational skills and attention to detail\n",
      "Great verbal and written communication skills\n",
      "A proactive self-starter eager to learn and develop their skills as part of a fast-paced team with a dedication to quality control over projects\n",
      "Experience in social media marketing preferred\n",
      "\n",
      "\n",
      "Your resume matches about 50.09% of the job description:Social Media Marketing Specialist.txt\n",
      "﻿User Experience (UX) Designer\n",
      "We are looking for a User Experience Designer. This is a client facing role that includes leading research in the form of client and customer interviews, persona development, buyers journey creation, content audits, conversion optimization, and usability testing. \n",
      "The successful candidate should be a passionate, detail-oriented individual who will work as a communicative team player and deliver high-quality work. You will be responsible for improving how INSOLAR product feels, and help create an enjoyable experience for our customers. \n",
      "Responsibilities often include:\n",
      "Consulting with clients to understand their goals and explaining research results\n",
      "Conducting usability testing\n",
      "Developing personas and usage scenarios\n",
      "Analyzing user feedback and activity, and iterating to enhance the user experience\n",
      "Assisting with content development\n",
      "Conducting competitor and customer analysis \n",
      "\n",
      "\n",
      "Your resume matches about 51.9% of the job description:User Experience (UX) Designer.txt\n",
      "﻿Web Developer\n",
      "We are looking for an outstanding Web Developer who is responsible for designing, coding and modifying websites, from layout to function. The successful candidate should strive to create visually appealing sites that feature user-friendly design and clear navigation.\n",
      "Essential duties and responsibilities includes:\n",
      "Write well designed, testable, efficient code by using best software development practices\n",
      "Create website layout/user interface by using standard HTML/CSS practices\n",
      "Integrate data from various back-end services and databases\n",
      "Gather and refine specifications and requirements based on technical needs\n",
      "Create and maintain software documentation\n",
      "Be responsible for maintaining, expanding, and scaling our site\n",
      "Cooperate with Graphic designer to match visual design intent\n",
      "Important Skills/Traits:\n",
      "General web functions and standards.\n",
      "Experience in planning and delivering software platforms\n",
      "Top-notch programming skills and in-depth knowledge of Web Applications and programming languages such as HTML, CSS, JavaScript, JQuery and API's\n",
      "Functional knowledge or hands on design experience with Web Services (REST, SOAP, etc.) is needed to be successful in this position\n",
      "BS in computer science or a related field\n",
      "\n",
      "\n",
      "\n",
      "Your resume matches about 53.86% of the job description:Web Developer.txt\n",
      "Data Scientist.txt 62.99 % matching\n",
      "Data Analyst.txt 60.35 % matching\n",
      "Fashion Designer.txt 54.9 % matching\n",
      "Web Developer.txt 53.86 % matching\n",
      "Public Relations Coordinator.txt 52.73 % matching\n",
      "Your top job recommendations are:\n",
      "Data Scientist 62.99 % macthing|\n",
      "Data Analyst 60.35 % macthing|\n",
      "Fashion Designer 54.9 % macthing|\n",
      "Web Developer 53.86 % macthing|\n",
      "Public Relations Coordinator 52.73 % macthing|\n",
      "Your top job recommendations are:\n",
      "Data Scientist 62.99 % macthing|\n",
      "Data Analyst 60.35 % macthing|\n",
      "Fashion Designer 54.9 % macthing|\n",
      "Web Developer 53.86 % macthing|\n",
      "Public Relations Coordinator 52.73 % macthing|\n"
     ]
    }
   ],
   "source": [
    "print(process(pdf_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
