{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Indeed Job Scraping</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 1: Inspect Indeed Website</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.1 Import Libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.2 Format URL</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/jobs?q=Data%20Scientist&l=Irvine\n"
     ]
    }
   ],
   "source": [
    "job_name = 'Data Scientist'\n",
    "location = 'Irvine'\n",
    "\n",
    "job_name = job_name.replace(' ','%20')\n",
    "location = location.replace(' ','%20')\n",
    "\n",
    "url = 'https://www.indeed.com/jobs?q=' + job_name + '&l=' + location\n",
    "\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(job_name, location):\n",
    "    job_name = job_name.replace(' ','%20')\n",
    "    location = location.replace(' ','%20')\n",
    "    url = 'https://www.indeed.com/jobs?q=' + job_name + '&l=' + location\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.3 Get Page</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page retrieved\n",
      "0.3796968460083008\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "page = requests.get(url)\n",
    "if page.status_code == 200:\n",
    "    print('Page retrieved')\n",
    "else:\n",
    "    print('An error occurred.')\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 2: Scrape HTML Contents</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.1 Parse Page using BeautifulSoup</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10176229476928711\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "soup = BeautifulSoup(page.content,'html.parser')\n",
    "\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.2 Find Results Container</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = soup.find(id='resultsBody')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_results(url):\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content,'html.parser')\n",
    "        return soup.find(id='resultsBody')\n",
    "    except:\n",
    "        print('Cannot access the website.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4417150020599365\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "extract_results(url)\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.3 Find Number of Pages</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagecount_text = soup.find('div',id='searchCountPages').text\n",
    "index_of = pagecount_text.index('of')\n",
    "num_job = re.sub('[A-Za-z]','',pagecount_text[index_of+3:]).strip()\n",
    "num_job = int(num_job)\n",
    "num_page = int(num_job/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.indeed.com/jobs?q=Data%20Scientist&l=Irvine', 'https://www.indeed.com/jobs?q=Data%20Scientist&l=Irvine&start=10', 'https://www.indeed.com/jobs?q=Data%20Scientist&l=Irvine&start=20', 'https://www.indeed.com/jobs?q=Data%20Scientist&l=Irvine&start=30', 'https://www.indeed.com/jobs?q=Data%20Scientist&l=Irvine&start=40', 'https://www.indeed.com/jobs?q=Data%20Scientist&l=Irvine&start=50', 'https://www.indeed.com/jobs?q=Data%20Scientist&l=Irvine&start=60']\n"
     ]
    }
   ],
   "source": [
    "pages = [url]\n",
    "for i in range(1,num_page+1):\n",
    "    pages.append(url+'&start='+str(i*10))\n",
    "print(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_count(url):\n",
    "    try:\n",
    "        results = extract_results(url)\n",
    "        pagecount_text = results.find('div',id='searchCountPages').text\n",
    "        num_job = re.sub('[A-Za-z]','',pagecount_text[pagecount_text.index('of')+3:]).strip()\n",
    "        num_job = int(num_job)\n",
    "        num_page = int(num_job/10)\n",
    "        return num_page, num_job\n",
    "    except:\n",
    "        print('Cannot access the website.')\n",
    "\n",
    "def get_pages(url):\n",
    "    try:\n",
    "        num_page, num_job = get_page_count(url)\n",
    "        pages = [url]\n",
    "        for i in range(1,num_page+1):\n",
    "            pages.append(url+'&start='+str(i*10))\n",
    "        return pages\n",
    "    except:\n",
    "        print('Cannot access the website.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4950752258300781\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "get_page_count(url)\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6314396858215332\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "get_pages(url)\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.4 Find Job Card</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009655237197875977\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "jobs = results.find_all('div',class_='jobsearch-SerpJobCard unifiedRow row result')\n",
    "\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = jobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "job.find('h2',class_='title')\\\n",
    "        .find('a',{'data-tn-element':'jobTitle'}).text.replace('\\n','')\n",
    "\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "job_url = job.find('h2',class_='title')\\\n",
    "              .find('a',{'data-tn-element':'jobTitle'})['href']\n",
    "job_url = 'https://www.indeed.com'+job_url\n",
    "\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "company = job.find('span',class_='company').text.replace('\\n','')\n",
    "\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "location = job.find('div',class_='recJobLoc')['data-rc-loc'].replace('\\n','')\n",
    "\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5891828536987305\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "try:\n",
    "    job_page = requests.get(job_url)\n",
    "    job_soup = BeautifulSoup(job_page.content,'html.parser')\n",
    "    job_description = job_soup.find('div',class_='jobsearch-jobDescriptionText')\n",
    "except:\n",
    "    print('An error occurred when accessing the page for job',job_title)\n",
    "\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job_dict = {\n",
    "    'title':[],\n",
    "    'company':[],\n",
    "    'location':[],\n",
    "    'url':[],\n",
    "    'description':[]\n",
    "}\n",
    "\n",
    "for job in jobs:\n",
    "    job_title = job.find('h2',class_='title')\\\n",
    "                .find('a',{'data-tn-element':'jobTitle'}).text.replace('\\n','')\n",
    "    job_url = job.find('h2',class_='title')\\\n",
    "              .find('a',{'data-tn-element':'jobTitle'})['href']\n",
    "    job_url = 'https://www.indeed.com'+job_url\n",
    "    company = job.find('span',class_='company').text.replace('\\n','')\n",
    "    location = job.find('div',class_='recJobLoc')['data-rc-loc'].replace('\\n','')\n",
    "    \n",
    "    #Access job url page\n",
    "    job_page = requests.get(job_url)\n",
    "    description = []\n",
    "    if job_page.status_code == 200:\n",
    "        job_soup = BeautifulSoup(job_page.content,'html.parser')\n",
    "        job_description = job_soup.find('div',class_='jobsearch-jobDescriptionText')\n",
    "#         for p in job_description.find_all('p'):\n",
    "#             description.append(p.text)\n",
    "#         description = ' '.join(description).replace('\\n','')\n",
    "    else:\n",
    "        print('An error occurred when accessing the page for job',job_title)\n",
    "    job_dict['title'].append(job_title)\n",
    "    job_dict['company'].append(company)\n",
    "    job_dict['location'].append(location)\n",
    "    job_dict['url'].append(job_url)\n",
    "    job_dict['description'].append(job_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "def get_description(job):\n",
    "    qual_list = ['requirements','qualifications','required ','what you ll']\n",
    "    job = re.sub(r'<.+?>','\\n',str(job))\n",
    "    description = []\n",
    "    for p in job.split('\\n'):\n",
    "        description += [re.sub('[^A-Za-z]',' ',s).strip().lower() for s in sent_tokenize(p)]\n",
    "    for desc in description:\n",
    "        if any([qual in desc for qual in qual_list]):\n",
    "            end_index = description.index(desc)\n",
    "            break\n",
    "        elif desc == 'skill':\n",
    "            end_index = description.index(desc)\n",
    "        else:\n",
    "            end_index = len(description)\n",
    "    job_description = ' '.join(description[:end_index])\n",
    "    return job_description\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobs(url, limit = 50):\n",
    "    if True:\n",
    "        count = 0\n",
    "        job_dict = {\n",
    "            'title':[],\n",
    "            'company':[],\n",
    "            'location':[],\n",
    "            'url':[],\n",
    "            'description':[]\n",
    "        }\n",
    "        pages = get_pages(url)\n",
    "        num_page, num_job = get_page_count(url)\n",
    "        limit = min(limit, num_job)\n",
    "        for page in pages:\n",
    "            results = extract_results(page)\n",
    "            jobs = results.find_all('div',class_='jobsearch-SerpJobCard unifiedRow row result')\n",
    "            for job in jobs:\n",
    "                if count == limit:\n",
    "                    break\n",
    "                job_title = job.find('h2',class_='title')\\\n",
    "                            .find('a',{'data-tn-element':'jobTitle'}).text.replace('\\n','')\n",
    "                job_url = job.find('h2',class_='title')\\\n",
    "                          .find('a',{'data-tn-element':'jobTitle'})['href']\n",
    "                job_url = 'https://www.indeed.com'+job_url\n",
    "                company = job.find('span',class_='company').text.replace('\\n','')\n",
    "                location = job.find('div',class_='recJobLoc')['data-rc-loc'].replace('\\n','')\n",
    "\n",
    "                #Access job url page\n",
    "                job_page = requests.get(job_url)\n",
    "                try:\n",
    "                    job_soup = BeautifulSoup(job_page.content,'html.parser')\n",
    "                    job_description = job_soup.find('div',class_='jobsearch-jobDescriptionText')\n",
    "                    job_description = re.sub(r'<.+?>','\\n',str(job_description))\n",
    "                except:\n",
    "                    print('An error occurred when accessing the page for job',job_title)\n",
    "                job_dict['title'].append(job_title)\n",
    "                job_dict['company'].append(company)\n",
    "                job_dict['location'].append(location)\n",
    "                job_dict['url'].append(job_url)\n",
    "                job_dict['description'].append(job_description)\n",
    "                count += 1\n",
    "        return job_dict\n",
    "    else:\n",
    "        print('Cannot access the website.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.951276540756226\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "get_jobs(url)\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ULTIMATE STAFFING SERVICES</td>\n",
       "      <td>Irvine, CA</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>key responsibilities data science focusing on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Financial Data Analyst w/PE backed Heal...</td>\n",
       "      <td>Alliance Resource Group</td>\n",
       "      <td>Orange, CA</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>senior financial data analyst w healthcare eco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Spireon</td>\n",
       "      <td>Irvine, CA</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=4c35157d313d5...</td>\n",
       "      <td>this is us we have a bold vision to connect   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Karma Automotive LLC</td>\n",
       "      <td>Irvine, CA</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=f7fd2a35541c6...</td>\n",
       "      <td>overview southern california based karma is mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist (Must be on W2)</td>\n",
       "      <td>SoftNice Inc</td>\n",
       "      <td>Santa Ana, CA</td>\n",
       "      <td>https://www.indeed.com/company/Ramy-Infotech-I...</td>\n",
       "      <td>description analytic data model development qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Abtsus LLC</td>\n",
       "      <td>Santa Ana, CA</td>\n",
       "      <td>https://www.indeed.com/company/Abtsus-LLC/jobs...</td>\n",
       "      <td>responsibilities include developing sql querie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist (Fraud &amp; Game Surveillance)</td>\n",
       "      <td>NCSOFT</td>\n",
       "      <td>Aliso Viejo, CA</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=11cf149979176...</td>\n",
       "      <td>who we are ncsoft is a premiere digital entert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Driveway</td>\n",
       "      <td>Aliso Viejo, CA</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=8fccd5560141c...</td>\n",
       "      <td>we are looking for a data scientist who will s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist Expert</td>\n",
       "      <td>SAP</td>\n",
       "      <td>Newport Beach, CA</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=c8987900476dd...</td>\n",
       "      <td>requisition id  work area software design and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>First American</td>\n",
       "      <td>Santa Ana, CA</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=75a9ed1f5c6ac...</td>\n",
       "      <td>join our team as a global leader in providing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vans Data Scientist, Consumer Lifecycle Manage...</td>\n",
       "      <td>Vans</td>\n",
       "      <td>Costa Mesa, CA</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=fa10e993a5f8a...</td>\n",
       "      <td>job ad vans  be a part of the original it was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Vans Data Scientist, Consumer Lifecycle Manage...</td>\n",
       "      <td>VF Corporation</td>\n",
       "      <td>Costa Mesa, CA</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=0de497c1036e3...</td>\n",
       "      <td>job ad vans  be a part of the original it was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lead Data Scientist / Engineer</td>\n",
       "      <td>AWM Smart Shelf (Adroit Worldwide Media, Inc.)</td>\n",
       "      <td>Aliso Viejo, CA</td>\n",
       "      <td>https://www.indeed.com/company/Adroit-Worldwid...</td>\n",
       "      <td>lead data scientist   engineer   aliso viejo  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Crossover Health</td>\n",
       "      <td>San Clemente, CA</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=0000e5693c171...</td>\n",
       "      <td>job description  designs  develops and program...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gustaine</td>\n",
       "      <td>Orange, CA</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=423ed7681c952...</td>\n",
       "      <td>role summary   purpose highly motivated self d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                                      Data Scientist   \n",
       "1   Senior Financial Data Analyst w/PE backed Heal...   \n",
       "2                                      Data Scientist   \n",
       "3                                      Data Scientist   \n",
       "4               Senior Data Scientist (Must be on W2)   \n",
       "5                                    Sr. Data Analyst   \n",
       "6          Data Scientist (Fraud & Game Surveillance)   \n",
       "7                                      Data Scientist   \n",
       "8                               Data Scientist Expert   \n",
       "9                               Senior Data Scientist   \n",
       "10  Vans Data Scientist, Consumer Lifecycle Manage...   \n",
       "11  Vans Data Scientist, Consumer Lifecycle Manage...   \n",
       "12                     Lead Data Scientist / Engineer   \n",
       "13                                     Data Scientist   \n",
       "14                                     Data Scientist   \n",
       "\n",
       "                                           company           location  \\\n",
       "0                       ULTIMATE STAFFING SERVICES         Irvine, CA   \n",
       "1                          Alliance Resource Group         Orange, CA   \n",
       "2                                          Spireon         Irvine, CA   \n",
       "3                             Karma Automotive LLC         Irvine, CA   \n",
       "4                                     SoftNice Inc      Santa Ana, CA   \n",
       "5                                       Abtsus LLC      Santa Ana, CA   \n",
       "6                                           NCSOFT    Aliso Viejo, CA   \n",
       "7                                         Driveway    Aliso Viejo, CA   \n",
       "8                                              SAP  Newport Beach, CA   \n",
       "9                                   First American      Santa Ana, CA   \n",
       "10                                            Vans     Costa Mesa, CA   \n",
       "11                                  VF Corporation     Costa Mesa, CA   \n",
       "12  AWM Smart Shelf (Adroit Worldwide Media, Inc.)    Aliso Viejo, CA   \n",
       "13                                Crossover Health   San Clemente, CA   \n",
       "14                                        Gustaine         Orange, CA   \n",
       "\n",
       "                                                  url  \\\n",
       "0   https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "1   https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "2   https://www.indeed.com/rc/clk?jk=4c35157d313d5...   \n",
       "3   https://www.indeed.com/rc/clk?jk=f7fd2a35541c6...   \n",
       "4   https://www.indeed.com/company/Ramy-Infotech-I...   \n",
       "5   https://www.indeed.com/company/Abtsus-LLC/jobs...   \n",
       "6   https://www.indeed.com/rc/clk?jk=11cf149979176...   \n",
       "7   https://www.indeed.com/rc/clk?jk=8fccd5560141c...   \n",
       "8   https://www.indeed.com/rc/clk?jk=c8987900476dd...   \n",
       "9   https://www.indeed.com/rc/clk?jk=75a9ed1f5c6ac...   \n",
       "10  https://www.indeed.com/rc/clk?jk=fa10e993a5f8a...   \n",
       "11  https://www.indeed.com/rc/clk?jk=0de497c1036e3...   \n",
       "12  https://www.indeed.com/company/Adroit-Worldwid...   \n",
       "13  https://www.indeed.com/rc/clk?jk=0000e5693c171...   \n",
       "14  https://www.indeed.com/rc/clk?jk=423ed7681c952...   \n",
       "\n",
       "                                          description  \n",
       "0   key responsibilities data science focusing on ...  \n",
       "1   senior financial data analyst w healthcare eco...  \n",
       "2   this is us we have a bold vision to connect   ...  \n",
       "3   overview southern california based karma is mo...  \n",
       "4   description analytic data model development qu...  \n",
       "5   responsibilities include developing sql querie...  \n",
       "6   who we are ncsoft is a premiere digital entert...  \n",
       "7   we are looking for a data scientist who will s...  \n",
       "8   requisition id  work area software design and ...  \n",
       "9   join our team as a global leader in providing ...  \n",
       "10  job ad vans  be a part of the original it was ...  \n",
       "11  job ad vans  be a part of the original it was ...  \n",
       "12  lead data scientist   engineer   aliso viejo  ...  \n",
       "13  job description  designs  develops and program...  \n",
       "14  role summary   purpose highly motivated self d...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_dict = get_jobs(url)\n",
    "pd.DataFrame(job_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indeed_job(job_name, location, limit = 50):\n",
    "    url = get_url(job_name, location)\n",
    "    job_dict = get_jobs(url, limit = limit)\n",
    "    return job_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.53865075111389\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "get_indeed_job('Data Analyst','Irvine')\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': ['Data Scientist',\n",
       "  'Senior Financial Data Analyst w/PE backed Healthcare company',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Sr. Data Analyst',\n",
       "  'Senior Data Scientist (Must be on W2)'],\n",
       " 'company': ['ULTIMATE STAFFING SERVICES',\n",
       "  'Alliance Resource Group',\n",
       "  'Spireon',\n",
       "  'Karma Automotive LLC',\n",
       "  'Abtsus LLC',\n",
       "  'SoftNice Inc'],\n",
       " 'location': ['Irvine, CA',\n",
       "  'Orange, CA',\n",
       "  'Irvine, CA',\n",
       "  'Irvine, CA',\n",
       "  'Santa Ana, CA',\n",
       "  'Santa Ana, CA'],\n",
       " 'url': ['https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0BhfrGGbcblirJ0_oD-V1jJ9SBvie1turFDKTAe6KCgN7BX82dLaSd1WaQVgK8U-NkNxRBIOR-46o3D8g-bUriwU9Rzou_w9Rmhiu7UmLSnZdr3JhqueoTh37ZuCnrIIHT4vAOu50K_Yt1voSKTGLrTKdX1NIV7ZQezoJrCJqlkB3ctQ60j6eaM8WZZNVVlRkJQ91KE7SRj_p5UfjU-G3cQlZyh7aUoBhrYS2fpYggjahEH3eJ_V27r8oqnb2WHso5sBAGRufRUyMr8PcG26grI_ibnLv30qaEtS3Uzx4YwZVNsMZceCFfjRE-ZdC04XDhQyudruj7yfXA_jRt1Wz-ciznmJJm7Y0z7GH2f0XNxb5nrzxbBLiHxL2jH9YKl8BCDEMFXe5rGADsNPh0pGYDK5MGBNK1yukxW2Rdyjmz378guZXRYFGQnro3Ty5bKjpIbtbPJ_SvCZ2IhcBs36bQDfI9sHOsh56o79jz8Ms8zjmBAcojwt9Q99KLjy-ewEuwGVcqoVujGxzMyzOMVHrX_4Dba0HvizGbyrrdJYJCfo7s0qolU80pwf1uYJDLUJkGikTrvE9RCLhWkcOBCqf1kTs6ZKj60j1ho5zcFhYwOSE5x7SA0DNfVWZgPCSgeCYrvGjl_vDLt0PesSaOdb9_pg_WHRfHFhx2t_FgTU7WEVDnhV1fF9Y17&p=0&fvj=0&vjs=3',\n",
       "  'https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0BjmH7HTzVxP-LQS1bO7f3KW-MFw0-yRhS3OAf3fkLpGkMwkNFCNUb4t6155Auj6Q2wqqcLGGRShSfeIBrvYVNaX4CAxwHal7dSPObl4po1invC5OEcz732tGlXKV5AKlFLmDRHDvWScBjY6MzvXgSkkJOj2gxpIKVAms1ktc0ShG9LVcyz2VsO8V2uMErXUaG8zvw5v8hnY8C0w8OuW29uWBcHE08gNTQH8UJdffNh6VJjRQZUwf9kPl0xBpZlveCwfBUfXEQQBMViYXatJFFY9ZvPm7YGePoQCpEbcpAVdgYgkM4t_n6zV0lAstB8XsivSAv5sDzxhyrcW-HL9xA7p7H3AXmwc1ksIDJrIZFYAQzUYDAY3PuhWXrZIP_op781gIa5JZBbSWpXIT0aQmS6f_CvF95hGmoCdpp2HGsl4YVIQWXlnBcNYOE270nX2FDmt4N44FTgBSYIZaLuMhsvcN37lq3RhxDML6euCaR2Am_hyeM47ryBjhCcQspACWMeazo-AIvtHw==&p=1&fvj=1&vjs=3',\n",
       "  'https://www.indeed.com/rc/clk?jk=4c35157d313d550b&fccid=c309838685f63059&vjs=3',\n",
       "  'https://www.indeed.com/rc/clk?jk=f7fd2a35541c62d2&fccid=87d7af0ec9cd5df0&vjs=3',\n",
       "  'https://www.indeed.com/company/Abtsus-LLC/jobs/Senior-Data-Analyst-cbca7c0f5300e057?fccid=1d3074ca80c15a92&vjs=3',\n",
       "  'https://www.indeed.com/company/Ramy-Infotech-INC/jobs/Senior-Data-Scientist-19b0dfe7dc6d899b?fccid=a290ac4fb8fb476c&vjs=3'],\n",
       " 'description': ['key responsibilities data science focusing on the aspect of applying machine learning and ai capabilities to the clinical research function at the company this position will not only expose you to the emerging demand and growth of ml and ai in healthcare but allow you to experience and take part in its development the data scientist will work directly with the principal data scientist in the business excellence ai group the primary focus will be to assist the principal data scientist to embark on various ml and ai projects that hinge on the prospect of solving challenging business problems projects are ranging from creating data driven dashboards to building complex prediction models  image detection processing  and developing natural language processing capabilities conduct advanced research and engineering for machine learning  ml  and nlp solutions for healthcare related topics work with large scale healthcare datasets to develop and test your ml and nlp models take advantage of models developed internally and available from the community to solve research problems in healthcare work closely with the ai research team as well as the clinical team to transfer your proof of concept research prototypes into meaningful features within our products skills knowledge of python and sql required knowledge of bi preferred knowledge of tableau preferred hands on experience with data pre processing  modeling  and visualization proficient in python hands on experience with sql and nosql databases knowledge of machine learning libraries  scikit learn  tensorflow  and pytorch prior experience in working with tableau and or power bi good communication and team working skills experience of working with aws is a plus education  amp  experience',\n",
       "  'senior financial data analyst w healthcare economics background this is an excellent opportunity for a candidate that is looking to take their career to the next level and come in on the ground floor in a fast moving  dynamic company the position is broad and will be exposed to all aspects of operations great opportunity for someone to broaden their skill set and get exposure to a very sophisticated  technology driven healthcare company job description the sr  financial data analyst will review  analyze  and report on data from the company s reporting system which includes medical claims data  utilization data  pharmacy data  and other sources such as gl and accounting related entries this person will be responsible for creating adhoc reports and models to support the analysis of product line profitability  gross margin  and possible market expansion opportunities there will also be significant involvement in working cross functionally with departments  so great communication skills are key for success in this role job duties reconcile and verify the integrity of yearly and monthly financial data to the general ledger work with the fp amp a team to incorporate budget data and assumptions into the company s reporting system validate the integrity of claim payment and analyze contract rate trending impact and anomalies validate and reconcile key authorization admit and bed day metrics to actual paid claim data support regional vp s in providing analysis of monthly data and ad hoc reporting of key performance indicators support finance and operations in developing predictive kpi s to better forecast and manage the business work with all levels of staff to direct  assist  and explain financial analysis processes read and interpret contracts with regards to risk pool definitions for revenue  expense  carve outs and calculations update risk pool calculations and definitions for newly delegated entities  as well as contract amendments for existing entities analyze key drivers of risk pool surplus or deficits and communicate to appropriate internal parties',\n",
       "  'this is us we have a bold vision to connect    million vehicles by our customers come first we lead through innovation we win as one we act with integrity we adhere to our brand promise   to make the complex simple  the future predictable  and our customers successful with nearly   million connected vehicles today spireon is an exciting player in the growing connected car and internet of things  iot  technology categories we help people and businesses track and protect their most important assets with vehicle intelligence solutions that gather big data and provide the critical insights with easy to use dashboards and apps this is you we are looking for a data scientist  machine learning engineer to design and build convolutional neural networks for smart sensors spireon develops computer vision based smart sensors to detect environment and reports for the transportation sector as a machine learning engineer  you will implement cnn algorithms to run on smart sensors   you must be able to work across multiple teams to ensure project objectives are met responsibilities design and develop algorithms for challenging vision classification and detections problems research and develop statistical learning models for data analysis implementation of computer vision and ml algorithms collect data and analyze real world data deploy ml systems  inference at the edge   monitor metrics prototyping ml algorithms collaborate with product management and engineering departments to understand company needs and devise possible solutions keep up to date with latest technology trends communicate results and ideas to key decision makers',\n",
       "  'overview southern california based karma is more than just a car company although we are best known as a creator of soul stirring luxury electric vehicles  karma has emerged as a high tech incubator offering innovators a perfect platform to prove their emerging technologies every revero is designed at our headquarters in irvine and created with great individual care and world class craftsmanship at the karma innovation and customization center in moreno valley  ca the data scientist reporting to the manager  data sciences and innovation  is responsible for data collection analyze  extract  normalize  and label relevant data from multiple sources to provide interpretation and visualizations reports around key data driven projects responsibilities design and build new data set processes for modeling  data mining  and production purposes determine new ways to improve data and search quality  and predictive capabilities perform and interpret data studies and product experiments concerning new data sources or new uses for existing data sources develop prototypes  proof of concepts  algorithms  predictive models  and custom analysis create visualizations and reports to show insights obtained from data mining efforts interact with multiple internal and external sources in support of ongoing and proof of concept projects ensure timely  accurate and credible information is provided and interpreted and distilled into action driven information for diverse audiences attend trade shows  conferences and learning opportunity to familiarize with the industry leading trends in data sciences and predictive analytics to help drive karma s data sciences and technology department development other duties  as assigned',\n",
       "  'responsibilities include developing sql queries stored procedures to retrieve and analyze data to support digitization researching to identify underlying root cause for issues using data building dashboards to continuously monitor implemented solutions coordinating with operation management to gather suggestions for improvements performing ad hoc analytical requests and research projects for internal parties providing feedback to senior management for identified problem areas and providing proactive solutions this position requires years experience as a data analyst within the mortgage banking industry proficient in the manipulation and use of large and complex databases strong understanding of sql database and data warehouse concepts and structures strong quantitative skills with a proven ability to translate analysis into meaningful insights proficient in sql  power bi and ms office products  excel  word  powerpoint including pivot  graph and slicer techniques ability to create  compose and edit written materials and presentations excellent verbal  written and interpersonal communication skills job type  full time pay                            per year benefits k dental insurance health insurance paid time off vision insurance schedule monday to friday experience mortgage domain    years  required work remotely temporarily due to covid',\n",
       "  'description analytic data model development quality check of output from other developers data exploration research documentation of logic and results presentation of logic and results to team and stakeholders field team modernization intelligent decision management   build and support of new predictive data models coding transformation   build and support of new existing predictive data models ad hoc data analysis']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_indeed_job('Data Scientist','Irvine')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
